{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa156889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#Importing Our data set\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/dsrscientist/dataset3/main/weatherAUS.csv')\n",
    "data  #first and last 5 rows of data set.\n",
    "Date\tLocation\tMinTemp\tMaxTemp\tRainfall\tEvaporation\tSunshine\tWindGustDir\tWindGustSpeed\tWindDir9am\t...\tHumidity9am\tHumidity3pm\tPressure9am\tPressure3pm\tCloud9am\tCloud3pm\tTemp9am\tTemp3pm\tRainToday\tRainTomorrow\n",
    "0\t2008-12-01\tAlbury\t13.4\t22.9\t0.6\tNaN\tNaN\tW\t44.0\tW\t...\t71.0\t22.0\t1007.7\t1007.1\t8.0\tNaN\t16.9\t21.8\tNo\tNo\n",
    "1\t2008-12-02\tAlbury\t7.4\t25.1\t0.0\tNaN\tNaN\tWNW\t44.0\tNNW\t...\t44.0\t25.0\t1010.6\t1007.8\tNaN\tNaN\t17.2\t24.3\tNo\tNo\n",
    "2\t2008-12-03\tAlbury\t12.9\t25.7\t0.0\tNaN\tNaN\tWSW\t46.0\tW\t...\t38.0\t30.0\t1007.6\t1008.7\tNaN\t2.0\t21.0\t23.2\tNo\tNo\n",
    "3\t2008-12-04\tAlbury\t9.2\t28.0\t0.0\tNaN\tNaN\tNE\t24.0\tSE\t...\t45.0\t16.0\t1017.6\t1012.8\tNaN\tNaN\t18.1\t26.5\tNo\tNo\n",
    "4\t2008-12-05\tAlbury\t17.5\t32.3\t1.0\tNaN\tNaN\tW\t41.0\tENE\t...\t82.0\t33.0\t1010.8\t1006.0\t7.0\t8.0\t17.8\t29.7\tNo\tNo\n",
    "...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\n",
    "8420\t2017-06-21\tUluru\t2.8\t23.4\t0.0\tNaN\tNaN\tE\t31.0\tSE\t...\t51.0\t24.0\t1024.6\t1020.3\tNaN\tNaN\t10.1\t22.4\tNo\tNo\n",
    "8421\t2017-06-22\tUluru\t3.6\t25.3\t0.0\tNaN\tNaN\tNNW\t22.0\tSE\t...\t56.0\t21.0\t1023.5\t1019.1\tNaN\tNaN\t10.9\t24.5\tNo\tNo\n",
    "8422\t2017-06-23\tUluru\t5.4\t26.9\t0.0\tNaN\tNaN\tN\t37.0\tSE\t...\t53.0\t24.0\t1021.0\t1016.8\tNaN\tNaN\t12.5\t26.1\tNo\tNo\n",
    "8423\t2017-06-24\tUluru\t7.8\t27.0\t0.0\tNaN\tNaN\tSE\t28.0\tSSE\t...\t51.0\t24.0\t1019.4\t1016.5\t3.0\t2.0\t15.1\t26.0\tNo\tNo\n",
    "8424\t2017-06-25\tUluru\t14.9\tNaN\t0.0\tNaN\tNaN\tNaN\tNaN\tESE\t...\t62.0\t36.0\t1020.2\t1017.9\t8.0\t8.0\t15.0\t20.9\tNo\tNaN\n",
    "8425 rows × 23 columns\n",
    "\n",
    "Exploratory Data Analysis (EDA)\n",
    "# Check the dimension of our DataSet\n",
    "data.shape\n",
    "(8425, 23)\n",
    "we have a total of 8425 records with 23 features\n",
    "\n",
    "#Let us check the name of our columns\n",
    "data.columns\n",
    "Index(['Date', 'Location', 'MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation',\n",
    "       'Sunshine', 'WindGustDir', 'WindGustSpeed', 'WindDir9am', 'WindDir3pm',\n",
    "       'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm',\n",
    "       'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am',\n",
    "       'Temp3pm', 'RainToday', 'RainTomorrow'],\n",
    "      dtype='object')\n",
    "# Check the data types of our \n",
    "data.dtypes\n",
    "Date              object\n",
    "Location          object\n",
    "MinTemp          float64\n",
    "MaxTemp          float64\n",
    "Rainfall         float64\n",
    "Evaporation      float64\n",
    "Sunshine         float64\n",
    "WindGustDir       object\n",
    "WindGustSpeed    float64\n",
    "WindDir9am        object\n",
    "WindDir3pm        object\n",
    "WindSpeed9am     float64\n",
    "WindSpeed3pm     float64\n",
    "Humidity9am      float64\n",
    "Humidity3pm      float64\n",
    "Pressure9am      float64\n",
    "Pressure3pm      float64\n",
    "Cloud9am         float64\n",
    "Cloud3pm         float64\n",
    "Temp9am          float64\n",
    "Temp3pm          float64\n",
    "RainToday         object\n",
    "RainTomorrow      object\n",
    "dtype: object\n",
    "So we have 16 Numeric datatypes and 7 Object type data types\n",
    "\n",
    "# Check the info about our dataset\n",
    "data.info()\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 8425 entries, 0 to 8424\n",
    "Data columns (total 23 columns):\n",
    " #   Column         Non-Null Count  Dtype  \n",
    "---  ------         --------------  -----  \n",
    " 0   Date           8425 non-null   object \n",
    " 1   Location       8425 non-null   object \n",
    " 2   MinTemp        8350 non-null   float64\n",
    " 3   MaxTemp        8365 non-null   float64\n",
    " 4   Rainfall       8185 non-null   float64\n",
    " 5   Evaporation    4913 non-null   float64\n",
    " 6   Sunshine       4431 non-null   float64\n",
    " 7   WindGustDir    7434 non-null   object \n",
    " 8   WindGustSpeed  7434 non-null   float64\n",
    " 9   WindDir9am     7596 non-null   object \n",
    " 10  WindDir3pm     8117 non-null   object \n",
    " 11  WindSpeed9am   8349 non-null   float64\n",
    " 12  WindSpeed3pm   8318 non-null   float64\n",
    " 13  Humidity9am    8366 non-null   float64\n",
    " 14  Humidity3pm    8323 non-null   float64\n",
    " 15  Pressure9am    7116 non-null   float64\n",
    " 16  Pressure3pm    7113 non-null   float64\n",
    " 17  Cloud9am       6004 non-null   float64\n",
    " 18  Cloud3pm       5970 non-null   float64\n",
    " 19  Temp9am        8369 non-null   float64\n",
    " 20  Temp3pm        8329 non-null   float64\n",
    " 21  RainToday      8185 non-null   object \n",
    " 22  RainTomorrow   8186 non-null   object \n",
    "dtypes: float64(16), object(7)\n",
    "memory usage: 1.5+ MB\n",
    "From this we can identity that many columns have null values\n",
    "\n",
    "# Check the null value counts\n",
    "data.isna().sum()\n",
    "Date                0\n",
    "Location            0\n",
    "MinTemp            75\n",
    "MaxTemp            60\n",
    "Rainfall          240\n",
    "Evaporation      3512\n",
    "Sunshine         3994\n",
    "WindGustDir       991\n",
    "WindGustSpeed     991\n",
    "WindDir9am        829\n",
    "WindDir3pm        308\n",
    "WindSpeed9am       76\n",
    "WindSpeed3pm      107\n",
    "Humidity9am        59\n",
    "Humidity3pm       102\n",
    "Pressure9am      1309\n",
    "Pressure3pm      1312\n",
    "Cloud9am         2421\n",
    "Cloud3pm         2455\n",
    "Temp9am            56\n",
    "Temp3pm            96\n",
    "RainToday         240\n",
    "RainTomorrow      239\n",
    "dtype: int64\n",
    "From this we can Notice that almost all feilds have null values, So we have to use imputation technigues for removing\n",
    "\n",
    "# Let us fund the Unique values present in our data\n",
    "data.nunique()\n",
    "Date             3004\n",
    "Location           12\n",
    "MinTemp           285\n",
    "MaxTemp           331\n",
    "Rainfall          250\n",
    "Evaporation       116\n",
    "Sunshine          140\n",
    "WindGustDir        16\n",
    "WindGustSpeed      52\n",
    "WindDir9am         16\n",
    "WindDir3pm         16\n",
    "WindSpeed9am       34\n",
    "WindSpeed3pm       35\n",
    "Humidity9am        90\n",
    "Humidity3pm        94\n",
    "Pressure9am       384\n",
    "Pressure3pm       374\n",
    "Cloud9am            9\n",
    "Cloud3pm            9\n",
    "Temp9am           304\n",
    "Temp3pm           328\n",
    "RainToday           2\n",
    "RainTomorrow        2\n",
    "dtype: int64\n",
    "From this we can notice that only two few catagorical columns are available.\n",
    "\n",
    "#Now Check any duplicate data present or not, If present then we will drop them.\n",
    "data=data.drop_duplicates()\n",
    "data.shape\n",
    "(6762, 23)\n",
    "As we noticed earlier we had around 8425 records were present, but now only 6762 that means 1663 duplicate record were present in our data, so we have removed them\n",
    "\n",
    "Statistical description of our data\n",
    "data.describe().T\n",
    "count\tmean\tstd\tmin\t25%\t50%\t75%\tmax\n",
    "MinTemp\t6692.0\t13.109145\t5.569574\t-2.0\t9.0\t13.2\t17.5\t28.5\n",
    "MaxTemp\t6705.0\t24.098345\t6.156128\t8.2\t19.5\t23.5\t28.4\t45.5\n",
    "Rainfall\t6624.0\t2.780148\t10.591418\t0.0\t0.0\t0.0\t0.8\t371.0\n",
    "Evaporation\t3841.0\t5.302395\t4.436790\t0.0\t2.6\t4.6\t7.0\t145.0\n",
    "Sunshine\t3526.0\t7.890896\t3.785883\t0.0\t5.4\t9.0\t10.8\t13.9\n",
    "WindGustSpeed\t5820.0\t38.977663\t14.418577\t7.0\t30.0\t37.0\t48.0\t107.0\n",
    "WindSpeed9am\t6699.0\t12.782206\t9.833499\t0.0\t6.0\t11.0\t19.0\t63.0\n",
    "WindSpeed3pm\t6662.0\t17.571150\t9.620043\t0.0\t9.0\t17.0\t24.0\t83.0\n",
    "Humidity9am\t6708.0\t67.506559\t17.251733\t10.0\t56.0\t68.0\t81.0\t100.0\n",
    "Humidity3pm\t6666.0\t50.467147\t18.631086\t6.0\t38.0\t50.0\t63.0\t99.0\n",
    "Pressure9am\t5454.0\t1017.626311\t6.712043\t989.8\t1013.1\t1017.6\t1022.2\t1039.0\n",
    "Pressure3pm\t5451.0\t1015.119923\t6.646755\t982.9\t1010.3\t1015.1\t1019.6\t1036.0\n",
    "Cloud9am\t4896.0\t4.336806\t2.908324\t0.0\t1.0\t5.0\t7.0\t8.0\n",
    "Cloud3pm\t4860.0\t4.320988\t2.740519\t0.0\t1.0\t5.0\t7.0\t8.0\n",
    "Temp9am\t6711.0\t17.895038\t5.744117\t1.9\t13.8\t18.0\t22.2\t39.4\n",
    "Temp3pm\t6670.0\t22.708561\t6.012896\t7.3\t18.3\t22.1\t26.8\t44.1\n",
    "This is the statistical description of our data,\n",
    "\n",
    "As we noticed many feature contains null values the count is different for all.\n",
    "Many feature the minimum values is 0.\n",
    "Some features contains negative values also.\n",
    "Data Preprocessing\n",
    "#Now Let us find the values of each Features in our data\n",
    "for i in data.columns:\n",
    "        print(data[i].value_counts())\n",
    "        print('*'*100)\n",
    "2011-02-11    4\n",
    "2011-02-18    4\n",
    "2011-03-18    4\n",
    "2011-03-19    4\n",
    "2011-03-20    4\n",
    "             ..\n",
    "2016-11-03    1\n",
    "2016-11-02    1\n",
    "2016-11-01    1\n",
    "2016-10-31    1\n",
    "2013-06-08    1\n",
    "Name: Date, Length: 3004, dtype: int64\n",
    "****************************************************************************************************\n",
    "PerthAirport    1204\n",
    "Albury           907\n",
    "Newcastle        822\n",
    "Melbourne        811\n",
    "Williamtown      615\n",
    "CoffsHarbour     611\n",
    "Brisbane         579\n",
    "Penrith          482\n",
    "Darwin           250\n",
    "Wollongong       237\n",
    "Adelaide         205\n",
    "Uluru             39\n",
    "Name: Location, dtype: int64\n",
    "****************************************************************************************************\n",
    "13.2    58\n",
    "12.0    57\n",
    "14.8    53\n",
    "12.7    53\n",
    "10.8    52\n",
    "        ..\n",
    "26.6     1\n",
    "28.0     1\n",
    "26.9     1\n",
    "1.4      1\n",
    "26.0     1\n",
    "Name: MinTemp, Length: 285, dtype: int64\n",
    "****************************************************************************************************\n",
    "19.0    66\n",
    "19.8    62\n",
    "20.8    54\n",
    "23.8    54\n",
    "25.0    54\n",
    "        ..\n",
    "38.9     1\n",
    "10.3     1\n",
    "9.4      1\n",
    "42.5     1\n",
    "43.5     1\n",
    "Name: MaxTemp, Length: 331, dtype: int64\n",
    "****************************************************************************************************\n",
    "0.0      4334\n",
    "0.2       321\n",
    "0.4       144\n",
    "0.6        87\n",
    "1.2        69\n",
    "         ... \n",
    "73.8        1\n",
    "23.8        1\n",
    "61.2        1\n",
    "128.0       1\n",
    "40.0        1\n",
    "Name: Rainfall, Length: 250, dtype: int64\n",
    "****************************************************************************************************\n",
    "4.0      141\n",
    "3.0      125\n",
    "2.2      118\n",
    "2.4      116\n",
    "2.6      116\n",
    "        ... \n",
    "145.0      1\n",
    "33.8       1\n",
    "59.2       1\n",
    "20.8       1\n",
    "0.7        1\n",
    "Name: Evaporation, Length: 116, dtype: int64\n",
    "****************************************************************************************************\n",
    "0.0     119\n",
    "11.1     61\n",
    "11.0     59\n",
    "11.2     59\n",
    "9.2      56\n",
    "       ... \n",
    "2.5       5\n",
    "13.6      4\n",
    "13.8      2\n",
    "13.9      2\n",
    "13.5      1\n",
    "Name: Sunshine, Length: 140, dtype: int64\n",
    "****************************************************************************************************\n",
    "E      518\n",
    "SW     465\n",
    "N      459\n",
    "W      434\n",
    "WSW    420\n",
    "WNW    398\n",
    "SSE    390\n",
    "S      376\n",
    "SE     370\n",
    "ENE    357\n",
    "NE     300\n",
    "SSW    299\n",
    "NW     296\n",
    "NNE    287\n",
    "ESE    267\n",
    "NNW    184\n",
    "Name: WindGustDir, dtype: int64\n",
    "****************************************************************************************************\n",
    "39.0     346\n",
    "35.0     341\n",
    "37.0     332\n",
    "33.0     317\n",
    "31.0     305\n",
    "30.0     302\n",
    "41.0     285\n",
    "28.0     285\n",
    "43.0     237\n",
    "26.0     228\n",
    "24.0     225\n",
    "48.0     211\n",
    "22.0     201\n",
    "46.0     195\n",
    "50.0     191\n",
    "52.0     186\n",
    "44.0     181\n",
    "20.0     170\n",
    "54.0     150\n",
    "19.0     117\n",
    "56.0     111\n",
    "57.0     105\n",
    "17.0      88\n",
    "61.0      83\n",
    "59.0      80\n",
    "63.0      67\n",
    "15.0      57\n",
    "13.0      57\n",
    "65.0      50\n",
    "67.0      42\n",
    "72.0      42\n",
    "70.0      35\n",
    "69.0      35\n",
    "74.0      34\n",
    "76.0      25\n",
    "11.0      18\n",
    "80.0      15\n",
    "78.0      15\n",
    "85.0       9\n",
    "81.0       9\n",
    "9.0        6\n",
    "91.0       6\n",
    "83.0       5\n",
    "98.0       4\n",
    "93.0       4\n",
    "89.0       4\n",
    "94.0       2\n",
    "87.0       2\n",
    "7.0        2\n",
    "107.0      1\n",
    "102.0      1\n",
    "100.0      1\n",
    "Name: WindGustSpeed, dtype: int64\n",
    "****************************************************************************************************\n",
    "N      609\n",
    "SW     590\n",
    "NW     463\n",
    "SE     439\n",
    "ENE    397\n",
    "WSW    394\n",
    "SSW    368\n",
    "NE     364\n",
    "E      338\n",
    "NNE    337\n",
    "S      324\n",
    "WNW    301\n",
    "SSE    300\n",
    "W      299\n",
    "ESE    229\n",
    "NNW    216\n",
    "Name: WindDir9am, dtype: int64\n",
    "****************************************************************************************************\n",
    "SE     677\n",
    "WSW    499\n",
    "S      493\n",
    "NE     480\n",
    "SW     428\n",
    "SSE    421\n",
    "NW     400\n",
    "W      399\n",
    "E      392\n",
    "WNW    389\n",
    "ESE    363\n",
    "N      354\n",
    "ENE    348\n",
    "NNE    305\n",
    "SSW    277\n",
    "NNW    243\n",
    "Name: WindDir3pm, dtype: int64\n",
    "****************************************************************************************************\n",
    "0.0     730\n",
    "9.0     641\n",
    "4.0     595\n",
    "13.0    520\n",
    "7.0     482\n",
    "6.0     459\n",
    "11.0    456\n",
    "17.0    366\n",
    "15.0    344\n",
    "19.0    333\n",
    "20.0    314\n",
    "2.0     240\n",
    "24.0    228\n",
    "22.0    213\n",
    "28.0    169\n",
    "26.0    158\n",
    "31.0    107\n",
    "30.0     81\n",
    "35.0     51\n",
    "33.0     50\n",
    "37.0     40\n",
    "41.0     26\n",
    "39.0     21\n",
    "43.0     16\n",
    "46.0     16\n",
    "44.0     16\n",
    "52.0      8\n",
    "56.0      5\n",
    "50.0      5\n",
    "54.0      3\n",
    "48.0      3\n",
    "61.0      1\n",
    "57.0      1\n",
    "63.0      1\n",
    "Name: WindSpeed9am, dtype: int64\n",
    "****************************************************************************************************\n",
    "9.0     639\n",
    "19.0    509\n",
    "13.0    505\n",
    "11.0    458\n",
    "20.0    452\n",
    "17.0    446\n",
    "15.0    430\n",
    "24.0    383\n",
    "28.0    355\n",
    "22.0    342\n",
    "7.0     293\n",
    "4.0     283\n",
    "26.0    279\n",
    "6.0     220\n",
    "30.0    196\n",
    "0.0     192\n",
    "31.0    176\n",
    "33.0    112\n",
    "35.0     93\n",
    "37.0     85\n",
    "2.0      54\n",
    "39.0     49\n",
    "41.0     30\n",
    "46.0     20\n",
    "43.0     20\n",
    "44.0     11\n",
    "50.0      8\n",
    "56.0      6\n",
    "48.0      6\n",
    "52.0      5\n",
    "65.0      1\n",
    "83.0      1\n",
    "54.0      1\n",
    "61.0      1\n",
    "57.0      1\n",
    "Name: WindSpeed3pm, dtype: int64\n",
    "****************************************************************************************************\n",
    "68.0    163\n",
    "73.0    161\n",
    "69.0    152\n",
    "70.0    148\n",
    "74.0    148\n",
    "       ... \n",
    "17.0      2\n",
    "14.0      2\n",
    "16.0      2\n",
    "10.0      1\n",
    "15.0      1\n",
    "Name: Humidity9am, Length: 90, dtype: int64\n",
    "****************************************************************************************************\n",
    "46.0    157\n",
    "51.0    155\n",
    "54.0    154\n",
    "49.0    151\n",
    "52.0    150\n",
    "       ... \n",
    "8.0      10\n",
    "7.0       7\n",
    "98.0      6\n",
    "99.0      3\n",
    "6.0       3\n",
    "Name: Humidity3pm, Length: 94, dtype: int64\n",
    "****************************************************************************************************\n",
    "1019.2    42\n",
    "1018.7    41\n",
    "1014.8    41\n",
    "1020.0    40\n",
    "1019.6    39\n",
    "          ..\n",
    "1036.2     1\n",
    "997.3      1\n",
    "1002.1     1\n",
    "993.4      1\n",
    "1033.6     1\n",
    "Name: Pressure9am, Length: 384, dtype: int64\n",
    "****************************************************************************************************\n",
    "1017.8    46\n",
    "1018.0    41\n",
    "1016.1    40\n",
    "1017.9    39\n",
    "1017.4    39\n",
    "          ..\n",
    "990.8      1\n",
    "1028.0     1\n",
    "992.4      1\n",
    "1035.9     1\n",
    "1029.5     1\n",
    "Name: Pressure3pm, Length: 374, dtype: int64\n",
    "****************************************************************************************************\n",
    "7.0    1043\n",
    "1.0     922\n",
    "8.0     764\n",
    "0.0     521\n",
    "6.0     454\n",
    "5.0     341\n",
    "3.0     313\n",
    "2.0     311\n",
    "4.0     227\n",
    "Name: Cloud9am, dtype: int64\n",
    "****************************************************************************************************\n",
    "7.0    959\n",
    "1.0    921\n",
    "8.0    644\n",
    "6.0    489\n",
    "5.0    433\n",
    "2.0    428\n",
    "3.0    357\n",
    "0.0    332\n",
    "4.0    297\n",
    "Name: Cloud3pm, dtype: int64\n",
    "****************************************************************************************************\n",
    "14.8    62\n",
    "18.0    61\n",
    "20.6    57\n",
    "17.5    54\n",
    "18.3    52\n",
    "        ..\n",
    "2.5      1\n",
    "2.0      1\n",
    "3.4      1\n",
    "5.2      1\n",
    "30.2     1\n",
    "Name: Temp9am, Length: 304, dtype: int64\n",
    "****************************************************************************************************\n",
    "19.2    63\n",
    "19.0    61\n",
    "22.5    54\n",
    "21.7    54\n",
    "23.5    53\n",
    "        ..\n",
    "41.1     1\n",
    "40.9     1\n",
    "41.0     1\n",
    "38.0     1\n",
    "42.4     1\n",
    "Name: Temp3pm, Length: 328, dtype: int64\n",
    "****************************************************************************************************\n",
    "No     5052\n",
    "Yes    1572\n",
    "Name: RainToday, dtype: int64\n",
    "****************************************************************************************************\n",
    "No     5052\n",
    "Yes    1572\n",
    "Name: RainTomorrow, dtype: int64\n",
    "****************************************************************************************************\n",
    "From Above we can notice that there is no spacial character or space in between features, Also we noticed same number of values in RainToday and RainTomorrow, Let us check if they are same, if same we can remove one columns\n",
    "\n",
    "if data['RainToday'].equals(data['RainTomorrow']):\n",
    "    print ('Same Data')\n",
    "else:\n",
    "    print(\"Different Data\")\n",
    "Different Data\n",
    "So they are different, so we can proceed\n",
    "\n",
    "#Now We will convert date from object type to date type and then seperate day, month and year\n",
    "data['Date']=pd.to_datetime(data['Date'])\n",
    "data[\"Day\"] = data['Date'].dt.day\n",
    "data[\"Month\"] = data['Date'].dt.month\n",
    "data[\"Year\"] = data['Date'].dt.year\n",
    "# Now drop date coloumns from our data\n",
    "data.drop(\"Date\",axis=1,inplace=True)\n",
    "#As we removed around 1663 records let us check again null value sum\n",
    "data.isnull().sum()\n",
    "Location            0\n",
    "MinTemp            70\n",
    "MaxTemp            57\n",
    "Rainfall          138\n",
    "Evaporation      2921\n",
    "Sunshine         3236\n",
    "WindGustDir       942\n",
    "WindGustSpeed     942\n",
    "WindDir9am        794\n",
    "WindDir3pm        294\n",
    "WindSpeed9am       63\n",
    "WindSpeed3pm      100\n",
    "Humidity9am        54\n",
    "Humidity3pm        96\n",
    "Pressure9am      1308\n",
    "Pressure3pm      1311\n",
    "Cloud9am         1866\n",
    "Cloud3pm         1902\n",
    "Temp9am            51\n",
    "Temp3pm            92\n",
    "RainToday         138\n",
    "RainTomorrow      138\n",
    "Day                 0\n",
    "Month               0\n",
    "Year                0\n",
    "dtype: int64\n",
    "So the number has reduced much\n",
    "\n",
    "# Let us separate Numercial and Catagorical features\n",
    "# Checking for categorical columns\n",
    "categorical_col=[]\n",
    "for i in data.dtypes.index:\n",
    "    if data.dtypes[i]=='object':\n",
    "        categorical_col.append(i)\n",
    "print(\"Categorical columns are:\\n\",categorical_col)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Now checking for numerical columns\n",
    "numerical_col=[]\n",
    "for i in data.dtypes.index:\n",
    "    if data.dtypes[i]!='object':\n",
    "        numerical_col.append(i)\n",
    "print(\"Numerical columns are:\\n\",numerical_col)\n",
    "Categorical columns are:\n",
    " ['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday', 'RainTomorrow']\n",
    "\n",
    "\n",
    "Numerical columns are:\n",
    " ['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm', 'Day', 'Month', 'Year']\n",
    "# Now let us replace the NAN values in Other catagorical Coloumns by MODE \n",
    "\n",
    "df=pd.DataFrame()\n",
    "df['WindGustDir'] = data['WindGustDir'].fillna(data['WindGustDir'].mode()[0])\n",
    "df['WindDir9am'] = data['WindDir9am'].fillna(data['WindDir9am'].mode()[0])\n",
    "df['WindDir3pm'] = data['WindDir3pm'].fillna(data['WindDir3pm'].mode()[0])\n",
    "df['RainToday'] = data['RainToday'].fillna(data['RainToday'].mode()[0])\n",
    "df['RainTomorrow']=data['RainTomorrow'].fillna(data['RainTomorrow'].mode()[0])\n",
    "df['Location']=data['Location']\n",
    "df\n",
    "WindGustDir\tWindDir9am\tWindDir3pm\tRainToday\tRainTomorrow\tLocation\n",
    "0\tW\tW\tWNW\tNo\tNo\tAlbury\n",
    "1\tWNW\tNNW\tWSW\tNo\tNo\tAlbury\n",
    "2\tWSW\tW\tWSW\tNo\tNo\tAlbury\n",
    "3\tNE\tSE\tE\tNo\tNo\tAlbury\n",
    "4\tW\tENE\tNW\tNo\tNo\tAlbury\n",
    "...\t...\t...\t...\t...\t...\t...\n",
    "8420\tE\tSE\tENE\tNo\tNo\tUluru\n",
    "8421\tNNW\tSE\tN\tNo\tNo\tUluru\n",
    "8422\tN\tSE\tWNW\tNo\tNo\tUluru\n",
    "8423\tSE\tSSE\tN\tNo\tNo\tUluru\n",
    "8424\tE\tESE\tESE\tNo\tNo\tUluru\n",
    "6762 rows × 6 columns\n",
    "\n",
    "#Now impute values to other fields using this feature\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "# We can impute values to our numerical columns by using Iterative imputers\n",
    "itimp=IterativeImputer()\n",
    "befor_imp=pd.DataFrame(data[numerical_col])\n",
    "kk_df=pd.DataFrame(itimp.fit_transform(befor_imp),columns=numerical_col)\n",
    "kk_df\n",
    "MinTemp\tMaxTemp\tRainfall\tEvaporation\tSunshine\tWindGustSpeed\tWindSpeed9am\tWindSpeed3pm\tHumidity9am\tHumidity3pm\tPressure9am\tPressure3pm\tCloud9am\tCloud3pm\tTemp9am\tTemp3pm\tDay\tMonth\tYear\n",
    "0\t13.4\t22.900000\t0.6\t3.391685\t7.130509\t44.000000\t20.0\t24.0\t71.0\t22.0\t1007.7\t1007.1\t8.000000\t4.874826\t16.9\t21.8\t1.0\t12.0\t2008.0\n",
    "1\t7.4\t25.100000\t0.0\t4.149341\t12.628322\t44.000000\t4.0\t22.0\t44.0\t25.0\t1010.6\t1007.8\t1.135447\t1.451345\t17.2\t24.3\t2.0\t12.0\t2008.0\n",
    "2\t12.9\t25.700000\t0.0\t5.872974\t12.022633\t46.000000\t19.0\t26.0\t38.0\t30.0\t1007.6\t1008.7\t2.268447\t2.000000\t21.0\t23.2\t3.0\t12.0\t2008.0\n",
    "3\t9.2\t28.000000\t0.0\t3.771469\t13.091641\t24.000000\t11.0\t9.0\t45.0\t16.0\t1017.6\t1012.8\t0.505052\t0.825362\t18.1\t26.5\t4.0\t12.0\t2008.0\n",
    "4\t17.5\t32.300000\t1.0\t3.909425\t6.732299\t41.000000\t7.0\t20.0\t82.0\t33.0\t1010.8\t1006.0\t7.000000\t8.000000\t17.8\t29.7\t5.0\t12.0\t2008.0\n",
    "...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\n",
    "6757\t2.8\t23.400000\t0.0\t6.351080\t11.113943\t31.000000\t13.0\t11.0\t51.0\t24.0\t1024.6\t1020.3\t0.685550\t1.589567\t10.1\t22.4\t21.0\t6.0\t2017.0\n",
    "6758\t3.6\t25.300000\t0.0\t6.025810\t11.780452\t22.000000\t13.0\t9.0\t56.0\t21.0\t1023.5\t1019.1\t0.577039\t1.130006\t10.9\t24.5\t22.0\t6.0\t2017.0\n",
    "6759\t5.4\t26.900000\t0.0\t7.826086\t11.551481\t37.000000\t9.0\t9.0\t53.0\t24.0\t1021.0\t1016.8\t0.869720\t1.639326\t12.5\t26.1\t23.0\t6.0\t2017.0\n",
    "6760\t7.8\t27.000000\t0.0\t8.048489\t10.572988\t28.000000\t13.0\t7.0\t51.0\t24.0\t1019.4\t1016.5\t3.000000\t2.000000\t15.1\t26.0\t24.0\t6.0\t2017.0\n",
    "6761\t14.9\t21.689692\t0.0\t7.364270\t3.642095\t42.803274\t17.0\t17.0\t62.0\t36.0\t1020.2\t1017.9\t8.000000\t8.000000\t15.0\t20.9\t25.0\t6.0\t2017.0\n",
    "6762 rows × 19 columns\n",
    "\n",
    "df[numerical_col]=kk_df[numerical_col]\n",
    "df.shape\n",
    "(6762, 25)\n",
    "df.isna().sum()\n",
    "WindGustDir         0\n",
    "WindDir9am          0\n",
    "WindDir3pm          0\n",
    "RainToday           0\n",
    "RainTomorrow        0\n",
    "Location            0\n",
    "MinTemp          1663\n",
    "MaxTemp          1663\n",
    "Rainfall         1663\n",
    "Evaporation      1663\n",
    "Sunshine         1663\n",
    "WindGustSpeed    1663\n",
    "WindSpeed9am     1663\n",
    "WindSpeed3pm     1663\n",
    "Humidity9am      1663\n",
    "Humidity3pm      1663\n",
    "Pressure9am      1663\n",
    "Pressure3pm      1663\n",
    "Cloud9am         1663\n",
    "Cloud3pm         1663\n",
    "Temp9am          1663\n",
    "Temp3pm          1663\n",
    "Day              1663\n",
    "Month            1663\n",
    "Year             1663\n",
    "dtype: int64\n",
    "df.dropna(inplace=True)\n",
    "df.shape\n",
    "(5099, 25)\n",
    "So we have removed all null values from our data\n",
    "\n",
    "# Visaulize the same\n",
    "sns.heatmap(df.isna())\n",
    "<AxesSubplot:>\n",
    "\n",
    "So from this we can identify that all null values have been removed\n",
    "\n",
    "Visualization\n",
    "#1st Univarient analisys\n",
    "categorical_col\n",
    "['Location',\n",
    " 'WindGustDir',\n",
    " 'WindDir9am',\n",
    " 'WindDir3pm',\n",
    " 'RainToday',\n",
    " 'RainTomorrow']\n",
    "sns.countplot(df['Location'],hue=df['RainTomorrow'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "We can notice that we have maximum features from ALbury low data from wollongong\n",
    "\n",
    "print(df['WindGustDir'].value_counts())\n",
    "sns.countplot(df['WindGustDir'],hue=df['RainTomorrow'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "E      1143\n",
    "N       372\n",
    "SSE     364\n",
    "W       333\n",
    "S       326\n",
    "WNW     322\n",
    "SE      302\n",
    "SW      287\n",
    "WSW     261\n",
    "NNE     239\n",
    "NE      237\n",
    "SSW     216\n",
    "ENE     210\n",
    "NW      195\n",
    "ESE     162\n",
    "NNW     130\n",
    "Name: WindGustDir, dtype: int64\n",
    "\n",
    "From This we can notice that if wind direction is in East direction the the chances of Rain is very low, All other the cances is almost same\n",
    "\n",
    "print(df['WindDir9am'].value_counts())\n",
    "sns.countplot(df['WindDir9am'],hue=df['RainTomorrow'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "N      1235\n",
    "SW      539\n",
    "NW      433\n",
    "WSW     351\n",
    "SE      322\n",
    "SSW     291\n",
    "W       262\n",
    "WNW     258\n",
    "S       236\n",
    "SSE     234\n",
    "NE      203\n",
    "NNW     169\n",
    "NNE     166\n",
    "E       138\n",
    "ESE     136\n",
    "ENE     126\n",
    "Name: WindDir9am, dtype: int64\n",
    "\n",
    "For we can notice that if wind direction at 9 am is towards north direction then the chances of Rain is Low\n",
    "\n",
    "print(df['WindDir3pm'].value_counts())\n",
    "sns.countplot(df['WindDir3pm'],hue=df['RainTomorrow'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "SE     910\n",
    "S      443\n",
    "NE     424\n",
    "SSE    362\n",
    "NW     304\n",
    "N      285\n",
    "WNW    279\n",
    "ESE    276\n",
    "ENE    256\n",
    "E      252\n",
    "W      252\n",
    "NNE    245\n",
    "WSW    237\n",
    "SSW    214\n",
    "SW     213\n",
    "NNW    147\n",
    "Name: WindDir3pm, dtype: int64\n",
    "\n",
    "In this case if the Wind direction is towards South East then the chances of Rain is low\n",
    "\n",
    "Now let us plot with Numerical data and catagorical\n",
    "numerical_col        # Numercial data\n",
    "['MinTemp',\n",
    " 'MaxTemp',\n",
    " 'Rainfall',\n",
    " 'Evaporation',\n",
    " 'Sunshine',\n",
    " 'WindGustSpeed',\n",
    " 'WindSpeed9am',\n",
    " 'WindSpeed3pm',\n",
    " 'Humidity9am',\n",
    " 'Humidity3pm',\n",
    " 'Pressure9am',\n",
    " 'Pressure3pm',\n",
    " 'Cloud9am',\n",
    " 'Cloud3pm',\n",
    " 'Temp9am',\n",
    " 'Temp3pm',\n",
    " 'Day',\n",
    " 'Month',\n",
    " 'Year']\n",
    "#Let us find the fainfall at different location\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.xticks(rotation=90)\n",
    "sns.lineplot(df['Location'],df['Rainfall'],hue=df['RainTomorrow'])\n",
    "plt.show()\n",
    "\n",
    "From this we can notice that At coffsHarbour the rain fall is comparetevily high, But chances of rain tommorow is at Wollongong or Melbourne is low\n",
    "\n",
    "#Let us find the fainfall at minimum Temperature\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.xticks(rotation=90)\n",
    "sns.scatterplot(df['MinTemp'],df['Rainfall'],hue=df['RainTomorrow'])\n",
    "plt.show()\n",
    "\n",
    "High rain fall in temperature of 10 to 25\n",
    "\n",
    "#Let us find the rainfall at Max Temperature\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.xticks(rotation=90)\n",
    "sns.scatterplot(df['MaxTemp'],df['Rainfall'],hue=df['RainTomorrow'])\n",
    "plt.show()\n",
    "\n",
    "If the Maximum temperature is in between 15 to 30 then the rainfall is high\n",
    "\n",
    "#Let us find the rainfall at Evaporation\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.xticks(rotation=90)\n",
    "sns.scatterplot(df['Evaporation'],df['Rainfall'],hue=df['RainTomorrow'])\n",
    "plt.show()\n",
    "\n",
    "From this we can reasily identify some outliers are present, and high rain fall during evapuration at 20 to 30, and chances of Raining Tomorrow is also high during same rate\n",
    "\n",
    "#Let us find the rainfall at Sunshine\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.xticks(rotation=90)\n",
    "sns.scatterplot(df['Sunshine'],df['Rainfall'],hue=df['RainTomorrow'])\n",
    "plt.show()\n",
    "\n",
    "As Sunshine increases rain fall decreases, but IF sunshine is very high some chances of rain fall is there\n",
    "\n",
    "#Let us find the rainfall at WindGustSpeed\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.xticks(rotation=90)\n",
    "sns.scatterplot(df['WindGustSpeed'],df['Rainfall'],hue=df['RainTomorrow'])\n",
    "plt.show()\n",
    "\n",
    "Rain fall is in between 20 to 80 windgustspeed\n",
    "\n",
    "#Let us find the rainfall at Windspeed3pm\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.xticks(rotation=90)\n",
    "sns.scatterplot(df['WindSpeed3pm'],df['Rainfall'],hue=df['RainTomorrow'])\n",
    "plt.show()\n",
    "\n",
    "If wind speed 0 to 40 at noon then chances of Rainfall is high\n",
    "\n",
    "#Let us find the rainfall at WindSpeed9am\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.xticks(rotation=90)\n",
    "sns.scatterplot(df['WindSpeed9am'],df['Rainfall'],hue=df['RainTomorrow'])\n",
    "plt.show()\n",
    "\n",
    "If in morning there is wind then chances rain is high\n",
    "\n",
    "#Check is there any relation between windspeed9am with windspeed3pm\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.xticks(rotation=90)\n",
    "sns.scatterplot(df['WindSpeed9am'],df['WindSpeed3pm'],hue=df['RainTomorrow'])\n",
    "plt.show()\n",
    "\n",
    "This Shows there is a linear relation\n",
    "\n",
    "#Let us find the Windgustspeed at WindSpeed9am\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.xticks(rotation=90)\n",
    "sns.scatterplot(df['WindSpeed9am'],df['WindGustSpeed'],hue=df['RainTomorrow'])\n",
    "plt.show()\n",
    "\n",
    "Also have some linear relation\n",
    "\n",
    "plt.figure(figsize=[18,13])\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.title('Comparision between Humidity9am Rain_Fall')\n",
    "sns.scatterplot(df['Humidity9am'],df['Rainfall'],hue=df['RainTomorrow'])\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title('Comparision between Humidity3pm and Rainfall')\n",
    "sns.scatterplot(df['Humidity3pm'],df['Rainfall'],hue=df['RainTomorrow'])\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title('Comparision between Pressure9am and Rainfall')\n",
    "sns.scatterplot(df['Pressure9am'],df['Rainfall'],hue=df['RainTomorrow'])\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.title('Comparision between Pressure3pm and Rainfall')\n",
    "sns.scatterplot(df['Pressure3pm'],df['Rainfall'],hue=df['RainTomorrow'])\n",
    "plt.show()\n",
    "\n",
    "From Fig 1&2 we can notice if high Humidity is there then chaces of rain fall is high From Fig 3 &4 we can notice that at pressure in between 1000 to 1030 chances of rain fall is high\n",
    "\n",
    "plt.figure(figsize=[18,13])\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.title('Comparision between Cloud9am Rain_Fall')\n",
    "sns.scatterplot(df['Cloud9am'],df['Rainfall'],hue=df['RainTomorrow'])\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title('Comparision between Cloud3pm and Rainfall')\n",
    "sns.scatterplot(df['Cloud3pm'],df['Rainfall'],hue=df['RainTomorrow'],palette='hsv')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title('Comparision between Pressure9am and Humidity9am')\n",
    "sns.scatterplot(df['Pressure9am'],df['Humidity9am'],hue=df['RainTomorrow'])\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.title('Comparision between Humidity3pm and Humidity9am')\n",
    "sns.scatterplot(df['Humidity3pm'],df['Humidity9am'],hue=df['RainTomorrow'],palette='hsv')\n",
    "plt.show()\n",
    "\n",
    "From fig 1 & 2 As cloudy is high chances of rain is also high\n",
    "From Fig 3 As Pressure increases the humidity alos increasing\n",
    "Humidity 9am and 3pm have linear relation\n",
    "plt.figure(figsize=[18,13])\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.title('Comparision between WindGustDir & Rain_Fall')\n",
    "sns.lineplot(df['WindGustDir'],df['Rainfall'],hue=df['RainTomorrow'],palette='coolwarm')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title('Comparision between Winddir9am and Rainfall')\n",
    "sns.lineplot(df['WindDir9am'],df['Rainfall'],hue=df['RainTomorrow'],palette='cool')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title('Comparision between WindDir3pm and Rainfall')\n",
    "sns.lineplot(df['WindDir3pm'],df['Rainfall'],hue=df['RainTomorrow'],palette='spring')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.title('Comparision between RAinToday and Rainfall')\n",
    "sns.lineplot(df['RainToday'],df['Rainfall'],hue=df['RainTomorrow'],palette='hsv')\n",
    "plt.show()\n",
    "\n",
    "If windGustdir is from NNW to SW then chances of rainis too high and high rainfall is in that location, if it is in direction SE to E then Chances of rain is low\n",
    "If Winddir9am is from WSW to NW then chances of rain is High Similarly if winddirat9am is in N to WSW the rain fall will be low\n",
    "If Winddir3pm W to ESE chances of rain low, nut if it is in ESE to SSW or to S then rainfall willbe high\n",
    "If rainfall no rainfall today then chances of raining tomorow is high, and vice versa\n",
    "sns.pairplot(df,palette='spring',hue='RainTomorrow')\n",
    "plt.show()\n",
    "\n",
    "Conclusion\n",
    "High relation between rainfall and RainTomorrow.\n",
    "If it rainToday then Chances of raining tomorrow is less.\n",
    "Some linear relationships noticed.\n",
    "We notice Wind Direction have influence on rainfall.\n",
    "Identifying the outliers\n",
    "# Let's check the outliers by ploting box plot\n",
    "\n",
    "plt.figure(figsize=(25,35),facecolor='white')\n",
    "plotnumber=1\n",
    "for column in numerical_col:\n",
    "    if plotnumber<=23:\n",
    "        ax=plt.subplot(6,4,plotnumber)\n",
    "        sns.boxplot(df[column],palette=\"Set2_r\")\n",
    "        plt.xlabel(column,fontsize=20)\n",
    "    plotnumber+=1\n",
    "plt.tight_layout()\n",
    "\n",
    "Most of the features contains outliers, let us remove the out liners using ZScore method\n",
    "\n",
    "Removing outliers using Zscore method\n",
    "features=df[['MaxTemp','Rainfall','Evaporation','Sunshine','WindGustSpeed','WindSpeed9am','WindSpeed3pm','Humidity9am','Pressure9am','Pressure3pm','Temp9am','Temp3pm']]\n",
    "\n",
    "# Using zscore to remove outliers\n",
    "from scipy.stats import zscore\n",
    "\n",
    "z=np.abs(zscore(features))\n",
    "\n",
    "z \n",
    "MaxTemp\tRainfall\tEvaporation\tSunshine\tWindGustSpeed\tWindSpeed9am\tWindSpeed3pm\tHumidity9am\tPressure9am\tPressure3pm\tTemp9am\tTemp3pm\n",
    "0\t0.229987\t0.205244\t0.398878\t0.143002\t0.585970\t1.015416\t0.813279\t0.128103\t1.766860\t1.411133\t0.215139\t0.187819\n",
    "1\t0.134071\t0.257142\t0.215776\t1.408207\t0.585970\t0.780844\t0.602789\t1.443096\t1.265458\t1.289729\t0.162886\t0.236069\n",
    "2\t0.233360\t0.257142\t0.200773\t1.237311\t0.728578\t0.903150\t1.023769\t1.792251\t1.784150\t1.133638\t0.498993\t0.049559\n",
    "3\t0.613966\t0.257142\t0.307096\t1.538932\t0.840108\t0.005020\t0.765395\t1.384903\t0.055177\t0.422557\t0.006125\t0.609090\n",
    "4\t1.325534\t0.170645\t0.273756\t0.255357\t0.372059\t0.444045\t0.392299\t0.768221\t1.230878\t1.601911\t0.058379\t1.151667\n",
    "...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\n",
    "6757\t0.147247\t0.257142\t0.316316\t0.980924\t0.340981\t0.229553\t0.554905\t1.035748\t1.155104\t0.878200\t1.399554\t0.086085\n",
    "6758\t0.167167\t0.257142\t0.237709\t1.168980\t0.982716\t0.229553\t0.765395\t0.744785\t0.964917\t0.670079\t1.260211\t0.269980\n",
    "6759\t0.431937\t0.257142\t0.672780\t1.104376\t0.086843\t0.219512\t0.765395\t0.919363\t0.532674\t0.271180\t0.981525\t0.541268\n",
    "6760\t0.448485\t0.257142\t0.726528\t0.828294\t0.554892\t0.229553\t0.975885\t1.035748\t0.256038\t0.219150\t0.528661\t0.524313\n",
    "6761\t0.430270\t0.257142\t0.561173\t1.127259\t0.500639\t0.678618\t0.076564\t0.395630\t0.394356\t0.461958\t0.546079\t0.340418\n",
    "5099 rows × 12 columns\n",
    "\n",
    "# Creating new dataframe\n",
    "new_df = df[(z<3).all(axis=1)] \n",
    "new_df\n",
    "WindGustDir\tWindDir9am\tWindDir3pm\tRainToday\tRainTomorrow\tLocation\tMinTemp\tMaxTemp\tRainfall\tEvaporation\t...\tHumidity3pm\tPressure9am\tPressure3pm\tCloud9am\tCloud3pm\tTemp9am\tTemp3pm\tDay\tMonth\tYear\n",
    "0\tW\tW\tWNW\tNo\tNo\tAlbury\t13.4\t22.900000\t0.6\t3.391685\t...\t22.0\t1007.7\t1007.1\t8.000000\t4.874826\t16.9\t21.8\t1.0\t12.0\t2008.0\n",
    "1\tWNW\tNNW\tWSW\tNo\tNo\tAlbury\t7.4\t25.100000\t0.0\t4.149341\t...\t25.0\t1010.6\t1007.8\t1.135447\t1.451345\t17.2\t24.3\t2.0\t12.0\t2008.0\n",
    "2\tWSW\tW\tWSW\tNo\tNo\tAlbury\t12.9\t25.700000\t0.0\t5.872974\t...\t30.0\t1007.6\t1008.7\t2.268447\t2.000000\t21.0\t23.2\t3.0\t12.0\t2008.0\n",
    "3\tNE\tSE\tE\tNo\tNo\tAlbury\t9.2\t28.000000\t0.0\t3.771469\t...\t16.0\t1017.6\t1012.8\t0.505052\t0.825362\t18.1\t26.5\t4.0\t12.0\t2008.0\n",
    "4\tW\tENE\tNW\tNo\tNo\tAlbury\t17.5\t32.300000\t1.0\t3.909425\t...\t33.0\t1010.8\t1006.0\t7.000000\t8.000000\t17.8\t29.7\t5.0\t12.0\t2008.0\n",
    "...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\n",
    "6757\tN\tN\tN\tNo\tNo\tAdelaide\t2.8\t23.400000\t0.0\t6.351080\t...\t24.0\t1024.6\t1020.3\t0.685550\t1.589567\t10.1\t22.4\t21.0\t6.0\t2017.0\n",
    "6758\tWNW\tNNE\tN\tNo\tYes\tAdelaide\t3.6\t25.300000\t0.0\t6.025810\t...\t21.0\t1023.5\t1019.1\t0.577039\t1.130006\t10.9\t24.5\t22.0\t6.0\t2017.0\n",
    "6759\tWSW\tSSW\tSW\tYes\tYes\tAdelaide\t5.4\t26.900000\t0.0\t7.826086\t...\t24.0\t1021.0\t1016.8\t0.869720\t1.639326\t12.5\t26.1\t23.0\t6.0\t2017.0\n",
    "6760\tWSW\tS\tW\tYes\tNo\tAdelaide\t7.8\t27.000000\t0.0\t8.048489\t...\t24.0\t1019.4\t1016.5\t3.000000\t2.000000\t15.1\t26.0\t24.0\t6.0\t2017.0\n",
    "6761\tNW\tN\tNW\tNo\tYes\tAdelaide\t14.9\t21.689692\t0.0\t7.364270\t...\t36.0\t1020.2\t1017.9\t8.000000\t8.000000\t15.0\t20.9\t25.0\t6.0\t2017.0\n",
    "4839 rows × 25 columns\n",
    "\n",
    "# Total Data Loss \n",
    "dataloss=(5099-4839)/5099\n",
    "dataloss*100\n",
    "5.099039027260247\n",
    "Using Z-Score, we are losing only 5% of data , that is affordable and we may proceed.\n",
    "\n",
    "Finding Skewness\n",
    "plt.figure(figsize=(25,35),facecolor='white')\n",
    "plotnumber=1\n",
    "for column in numerical_col:\n",
    "    if plotnumber<=23:\n",
    "        ax=plt.subplot(6,4,plotnumber)\n",
    "        sns.distplot(new_df[column],color=\"darkgreen\",hist=False,kde_kws={\"shade\": True})\n",
    "        plt.xlabel(column,fontsize=18)\n",
    "    plotnumber+=1\n",
    "plt.tight_layout()\n",
    "\n",
    "Few features like rainfall contains high skewness. Let us check using skew()\n",
    "\n",
    "new_df.skew()\n",
    "MinTemp         -0.137773\n",
    "MaxTemp          0.197290\n",
    "Rainfall         3.650157\n",
    "Evaporation      0.174545\n",
    "Sunshine        -0.288996\n",
    "WindGustSpeed    0.601910\n",
    "WindSpeed9am     0.756993\n",
    "WindSpeed3pm     0.426798\n",
    "Humidity9am     -0.273921\n",
    "Humidity3pm      0.098996\n",
    "Pressure9am     -0.109561\n",
    "Pressure3pm     -0.077155\n",
    "Cloud9am         0.024393\n",
    "Cloud3pm         0.096084\n",
    "Temp9am         -0.209469\n",
    "Temp3pm          0.243698\n",
    "Day              0.009663\n",
    "Month            0.033661\n",
    "Year             0.083311\n",
    "dtype: float64\n",
    "Removing Skewness using yeo-johnson method\n",
    "skew=['Rainfall','Evaporation','WindGustSpeed','WindSpeed9am','WindSpeed3pm']\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "scaler = PowerTransformer(method='yeo-johnson')\n",
    "\n",
    "new_df[skew] = scaler.fit_transform(new_df[skew].values)\n",
    "new_df[skew].head()\n",
    "Rainfall\tEvaporation\tWindGustSpeed\tWindSpeed9am\tWindSpeed3pm\n",
    "0\t0.048555\t-0.449326\t0.803420\t1.112653\t0.930441\n",
    "1\t-0.465737\t-0.191372\t0.803420\t-0.668855\t0.738956\n",
    "2\t-0.465737\t0.390325\t0.934713\t1.031915\t1.116634\n",
    "3\t-0.465737\t-0.319826\t-0.826674\t0.282632\t-0.698347\n",
    "4\t0.281386\t-0.272886\t0.598279\t-0.203514\t0.541547\n",
    "new_df[skew].skew()\n",
    "Rainfall        -4.981502\n",
    "Evaporation      0.086263\n",
    "WindGustSpeed   -0.012794\n",
    "WindSpeed9am    -0.132963\n",
    "WindSpeed3pm    -0.077357\n",
    "dtype: float64\n",
    "Skewness have been reduced, We can notice Rainfall is one of our Label so we can proceed\n",
    "\n",
    "# After removing skewness let's check how the data has been distributed in each column.\n",
    "\n",
    "plt.figure(figsize=(20,20), facecolor='white')\n",
    "plotnumber = 1\n",
    "\n",
    "for column in new_df[skew]:\n",
    "    if plotnumber<=4:\n",
    "        ax = plt.subplot(2,2,plotnumber)\n",
    "        sns.distplot(new_df[column],color='indigo',kde_kws={\"shade\": True},hist=False)\n",
    "        plt.xlabel(column,fontsize=15)\n",
    "    plotnumber+=1\n",
    "plt.show()\n",
    "\n",
    "# Removing skewness using square root method\n",
    "new_df[\"Rainfall\"] = np.cbrt(new_df[\"Rainfall\"])\n",
    "new_df.skew()  # again checking skewness\n",
    "MinTemp         -0.137773\n",
    "MaxTemp          0.197290\n",
    "Rainfall         1.096926\n",
    "Evaporation      0.086263\n",
    "Sunshine        -0.288996\n",
    "WindGustSpeed   -0.012794\n",
    "WindSpeed9am    -0.132963\n",
    "WindSpeed3pm    -0.077357\n",
    "Humidity9am     -0.273921\n",
    "Humidity3pm      0.098996\n",
    "Pressure9am     -0.109561\n",
    "Pressure3pm     -0.077155\n",
    "Cloud9am         0.024393\n",
    "Cloud3pm         0.096084\n",
    "Temp9am         -0.209469\n",
    "Temp3pm          0.243698\n",
    "Day              0.009663\n",
    "Month            0.033661\n",
    "Year             0.083311\n",
    "dtype: float64\n",
    "Now the Skewness reduced, and let us proceed further\n",
    "\n",
    "Encoding the categorical columns using Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "LE=LabelEncoder()\n",
    "new_df[categorical_col]= new_df[categorical_col].apply(LE.fit_transform)\n",
    "new_df[categorical_col]\n",
    "Location\tWindGustDir\tWindDir9am\tWindDir3pm\tRainToday\tRainTomorrow\n",
    "0\t1\t13\t13\t14\t0\t0\n",
    "1\t1\t14\t6\t15\t0\t0\n",
    "2\t1\t15\t13\t15\t0\t0\n",
    "3\t1\t4\t9\t0\t0\t0\n",
    "4\t1\t13\t1\t7\t0\t0\n",
    "...\t...\t...\t...\t...\t...\t...\n",
    "6757\t0\t3\t3\t3\t0\t0\n",
    "6758\t0\t14\t5\t3\t0\t1\n",
    "6759\t0\t15\t11\t12\t1\t1\n",
    "6760\t0\t15\t8\t13\t1\t0\n",
    "6761\t0\t7\t3\t7\t0\t1\n",
    "4839 rows × 6 columns\n",
    "\n",
    "So we have encoded our data, now let us find the other relations\n",
    "\n",
    "Correlation between the target variable and independent variables using HEAT map\n",
    "# Checking the correlation between features and the target\n",
    "cor = new_df.corr()\n",
    "cor\n",
    "WindGustDir\tWindDir9am\tWindDir3pm\tRainToday\tRainTomorrow\tLocation\tMinTemp\tMaxTemp\tRainfall\tEvaporation\t...\tHumidity3pm\tPressure9am\tPressure3pm\tCloud9am\tCloud3pm\tTemp9am\tTemp3pm\tDay\tMonth\tYear\n",
    "WindGustDir\t1.000000\t0.367967\t0.393584\t0.071513\t0.006166\t-0.147793\t-0.081854\t-0.069394\t-0.017777\t-0.046661\t...\t-0.111734\t-0.086622\t-0.052079\t0.009259\t-0.018267\t-0.072270\t-0.067763\t0.000404\t0.021164\t-0.212247\n",
    "WindDir9am\t0.367967\t1.000000\t0.201090\t0.122139\t-0.007133\t-0.021021\t0.069061\t-0.024063\t0.046053\t0.102758\t...\t-0.033417\t-0.058537\t-0.013349\t-0.003938\t0.004311\t0.075152\t-0.025337\t-0.021223\t0.017524\t-0.039959\n",
    "WindDir3pm\t0.393584\t0.201090\t1.000000\t0.083341\t-0.017381\t-0.050372\t-0.143353\t-0.157298\t0.042125\t-0.045528\t...\t-0.034395\t-0.026644\t0.030035\t0.043943\t0.032016\t-0.164988\t-0.160667\t-0.001424\t0.032329\t-0.021169\n",
    "RainToday\t0.071513\t0.122139\t0.083341\t1.000000\t0.294971\t0.010212\t0.102598\t-0.139564\t0.670205\t-0.057430\t...\t0.275839\t-0.032336\t0.016307\t0.268806\t0.240204\t-0.028751\t-0.143006\t0.001433\t-0.048330\t0.018636\n",
    "RainTomorrow\t0.006166\t-0.007133\t-0.017381\t0.294971\t1.000000\t0.012833\t0.096017\t-0.099118\t0.240868\t-0.046788\t...\t0.339144\t-0.037336\t-0.015301\t0.243258\t0.294422\t0.004357\t-0.127703\t0.003060\t-0.052404\t0.020604\n",
    "Location\t-0.147793\t-0.021021\t-0.050372\t0.010212\t0.012833\t1.000000\t0.109190\t-0.042359\t0.079019\t0.239948\t...\t0.188513\t0.073166\t0.086926\t0.115216\t0.143629\t0.063952\t-0.054065\t-0.001757\t-0.032383\t0.542482\n",
    "MinTemp\t-0.081854\t0.069061\t-0.143353\t0.102598\t0.096017\t0.109190\t1.000000\t0.739828\t0.139570\t0.601006\t...\t0.122702\t-0.489516\t-0.482624\t0.156774\t0.115432\t0.905063\t0.709154\t0.022301\t-0.204835\t0.030889\n",
    "MaxTemp\t-0.069394\t-0.024063\t-0.157298\t-0.139564\t-0.099118\t-0.042359\t0.739828\t1.000000\t-0.188904\t0.709351\t...\t-0.393091\t-0.406983\t-0.486397\t-0.287213\t-0.294340\t0.860738\t0.980235\t0.013752\t-0.128894\t0.059236\n",
    "Rainfall\t-0.017777\t0.046053\t0.042125\t0.670205\t0.240868\t0.079019\t0.139570\t-0.188904\t1.000000\t-0.112612\t...\t0.408603\t-0.100413\t-0.026077\t0.405943\t0.351286\t-0.040751\t-0.200529\t-0.000003\t-0.033031\t0.035458\n",
    "Evaporation\t-0.046661\t0.102758\t-0.045528\t-0.057430\t-0.046788\t0.239948\t0.601006\t0.709351\t-0.112612\t1.000000\t...\t-0.335572\t-0.336950\t-0.350884\t-0.172180\t-0.230072\t0.692513\t0.688649\t0.003909\t0.020956\t0.378581\n",
    "Sunshine\t0.013827\t0.006796\t-0.060204\t-0.295733\t-0.313694\t-0.156778\t0.073398\t0.577814\t-0.431385\t0.441297\t...\t-0.745252\t-0.073435\t-0.148891\t-0.786976\t-0.805850\t0.347121\t0.607436\t-0.019258\t0.080068\t-0.028905\n",
    "WindGustSpeed\t0.168608\t0.193863\t0.025146\t0.039725\t0.078210\t0.013737\t0.292443\t0.240020\t0.075311\t0.423384\t...\t-0.139680\t-0.424821\t-0.382195\t0.001073\t0.041553\t0.314290\t0.205922\t-0.010010\t0.061452\t-0.033935\n",
    "WindSpeed9am\t0.235467\t0.407074\t-0.002367\t0.061240\t0.052306\t-0.020133\t0.232785\t0.103581\t0.047429\t0.281645\t...\t-0.068740\t-0.236920\t-0.185891\t-0.006402\t0.039211\t0.246031\t0.088914\t-0.010495\t0.038621\t-0.067726\n",
    "WindSpeed3pm\t0.150769\t0.198193\t-0.026377\t-0.010425\t-0.014810\t-0.012967\t0.242018\t0.200175\t0.007508\t0.301268\t...\t-0.108828\t-0.298303\t-0.249812\t-0.033194\t-0.054630\t0.300441\t0.183882\t-0.007642\t0.050436\t-0.054984\n",
    "Humidity9am\t-0.119860\t-0.177281\t-0.008537\t0.256925\t0.200316\t0.109831\t-0.114346\t-0.386030\t0.409543\t-0.491655\t...\t0.628277\t0.189486\t0.210957\t0.530369\t0.420542\t-0.371675\t-0.380397\t0.011701\t-0.140823\t0.094771\n",
    "Humidity3pm\t-0.111734\t-0.033417\t-0.034395\t0.275839\t0.339144\t0.188513\t0.122702\t-0.393091\t0.408603\t-0.335572\t...\t1.000000\t0.040785\t0.111498\t0.578490\t0.620441\t-0.076099\t-0.461916\t0.032333\t-0.085517\t-0.039025\n",
    "Pressure9am\t-0.086622\t-0.058537\t-0.026644\t-0.032336\t-0.037336\t0.073166\t-0.489516\t-0.406983\t-0.100413\t-0.336950\t...\t0.040785\t1.000000\t0.963198\t-0.082048\t-0.066289\t-0.483372\t-0.368648\t-0.038894\t0.022430\t0.108720\n",
    "Pressure3pm\t-0.052079\t-0.013349\t0.030035\t0.016307\t-0.015301\t0.086926\t-0.482624\t-0.486397\t-0.026077\t-0.350884\t...\t0.111498\t0.963198\t1.000000\t-0.005773\t0.008579\t-0.503896\t-0.456350\t-0.029317\t0.004946\t0.103076\n",
    "Cloud9am\t0.009259\t-0.003938\t0.043943\t0.268806\t0.243258\t0.115216\t0.156774\t-0.287213\t0.405943\t-0.172180\t...\t0.578490\t-0.082048\t-0.005773\t1.000000\t0.700128\t-0.107495\t-0.307239\t0.012197\t-0.044187\t0.044150\n",
    "Cloud3pm\t-0.018267\t0.004311\t0.032016\t0.240204\t0.294422\t0.143629\t0.115432\t-0.294340\t0.351286\t-0.230072\t...\t0.620441\t-0.066289\t0.008579\t0.700128\t1.000000\t-0.087512\t-0.347860\t0.031357\t-0.042638\t0.049007\n",
    "Temp9am\t-0.072270\t0.075152\t-0.164988\t-0.028751\t0.004357\t0.063952\t0.905063\t0.860738\t-0.040751\t0.692513\t...\t-0.076099\t-0.483372\t-0.503896\t-0.107495\t-0.087512\t1.000000\t0.828433\t0.018715\t-0.118569\t0.010964\n",
    "Temp3pm\t-0.067763\t-0.025337\t-0.160667\t-0.143006\t-0.127703\t-0.054065\t0.709154\t0.980235\t-0.200529\t0.688649\t...\t-0.461916\t-0.368648\t-0.456350\t-0.307239\t-0.347860\t0.828433\t1.000000\t0.012808\t-0.146544\t0.065026\n",
    "Day\t0.000404\t-0.021223\t-0.001424\t0.001433\t0.003060\t-0.001757\t0.022301\t0.013752\t-0.000003\t0.003909\t...\t0.032333\t-0.038894\t-0.029317\t0.012197\t0.031357\t0.018715\t0.012808\t1.000000\t-0.004940\t0.004965\n",
    "Month\t0.021164\t0.017524\t0.032329\t-0.048330\t-0.052404\t-0.032383\t-0.204835\t-0.128894\t-0.033031\t0.020956\t...\t-0.085517\t0.022430\t0.004946\t-0.044187\t-0.042638\t-0.118569\t-0.146544\t-0.004940\t1.000000\t-0.070271\n",
    "Year\t-0.212247\t-0.039959\t-0.021169\t0.018636\t0.020604\t0.542482\t0.030889\t0.059236\t0.035458\t0.378581\t...\t-0.039025\t0.108720\t0.103076\t0.044150\t0.049007\t0.010964\t0.065026\t0.004965\t-0.070271\t1.000000\n",
    "25 rows × 25 columns\n",
    "\n",
    "This gives the correlation between the denpendent and independent variables. We can visualize this by plotting heat map.\n",
    "\n",
    "# Visualizing the correlation matrix by plotting heat map.\n",
    "plt.figure(figsize=(25,25))\n",
    "sns.heatmap(new_df.corr(),linewidths=.1,vmin=-1, vmax=1, fmt='.1g',linecolor=\"black\", annot = True, annot_kws={'size':10},cmap=\"cool\")\n",
    "<AxesSubplot:>\n",
    "\n",
    "From this we can notice some multi colinearity between some features, so we will use VIF techniques to remove highly related feature\n",
    "\n",
    "Visualizing the correlation between label and features using bar plot\n",
    "plt.figure(figsize=(20,10))\n",
    "new_df.corr()['RainTomorrow'].sort_values(ascending=False).drop(['RainTomorrow']).plot(kind='bar',color='indigo')\n",
    "plt.xlabel('Feature',fontsize=14)\n",
    "plt.ylabel('Target',fontsize=14)\n",
    "plt.title('correlation between label and feature using bar plot',fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "This is for Classificaion Problem the relation between RainTomorrow as our Label, Some features does not have much relation between Label\n",
    "\n",
    "Feature Scaling using Standard Scalarization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#Separate Label and Features\n",
    "x=new_df.drop('RainTomorrow',axis=1)\n",
    "y=new_df.RainTomorrow\n",
    "scaler = StandardScaler()\n",
    "x = pd.DataFrame(scaler.fit_transform(x), columns=x.columns)\n",
    "x.head()\n",
    "WindGustDir\tWindDir9am\tWindDir3pm\tRainToday\tLocation\tMinTemp\tMaxTemp\tRainfall\tEvaporation\tSunshine\t...\tHumidity3pm\tPressure9am\tPressure3pm\tCloud9am\tCloud3pm\tTemp9am\tTemp3pm\tDay\tMonth\tYear\n",
    "0\t1.247965\t1.213389\t1.541063\t-0.560882\t-1.379334\t0.048488\t-0.226612\t0.806117\t-0.449326\t-0.154832\t...\t-1.588149\t-1.883671\t-1.502182\t1.479615\t0.327698\t-0.202854\t-0.185536\t-1.668284\t1.667302\t-1.743795\n",
    "1\t1.441737\t-0.358897\t1.779808\t-0.560882\t-1.379334\t-1.001527\t0.145232\t-0.615681\t-0.191372\t1.435521\t...\t-1.426422\t-1.357451\t-1.375007\t-1.110178\t-1.049117\t-0.150355\t0.247241\t-1.554771\t1.667302\t-1.743795\n",
    "2\t1.635509\t1.213389\t1.779808\t-0.560882\t-1.379334\t-0.039013\t0.246644\t-0.615681\t0.390325\t1.260313\t...\t-1.156876\t-1.901817\t-1.211498\t-0.682731\t-0.828466\t0.514633\t0.056819\t-1.441258\t1.667302\t-1.743795\n",
    "3\t-0.495982\t0.314940\t-1.801369\t-0.560882\t-1.379334\t-0.686522\t0.635391\t-0.615681\t-0.319826\t1.569545\t...\t-1.911604\t-0.087263\t-0.466621\t-1.348008\t-1.300868\t0.007143\t0.628084\t-1.327745\t1.667302\t-1.743795\n",
    "4\t1.247965\t-1.481959\t-0.130153\t-0.560882\t-1.379334\t0.765999\t1.362178\t1.168404\t-0.272886\t-0.270022\t...\t-0.995149\t-1.321159\t-1.702027\t1.102344\t1.584544\t-0.045357\t1.182039\t-1.214232\t1.667302\t-1.743795\n",
    "5 rows × 24 columns\n",
    "\n",
    "Checking Variance Inflation Factor(VIF)\n",
    "# Finding varience inflation factor in each scaled column i.e, x.shape[1] (1/(1-R2))\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF values\"] = [variance_inflation_factor(x.values,i)\n",
    "              for i in range(len(x.columns))]\n",
    "vif[\"Features\"] = x.columns\n",
    "\n",
    "# Let's check the values\n",
    "vif\n",
    "VIF values\tFeatures\n",
    "0\t1.475585\tWindGustDir\n",
    "1\t1.404584\tWindDir9am\n",
    "2\t1.307690\tWindDir3pm\n",
    "3\t1.900497\tRainToday\n",
    "4\t1.655218\tLocation\n",
    "5\t12.622109\tMinTemp\n",
    "6\t38.589724\tMaxTemp\n",
    "7\t2.337321\tRainfall\n",
    "8\t5.093665\tEvaporation\n",
    "9\t10.512002\tSunshine\n",
    "10\t3.840994\tWindGustSpeed\n",
    "11\t2.276619\tWindSpeed9am\n",
    "12\t2.952324\tWindSpeed3pm\n",
    "13\t5.015941\tHumidity9am\n",
    "14\t6.986194\tHumidity3pm\n",
    "15\t23.012086\tPressure9am\n",
    "16\t22.783839\tPressure3pm\n",
    "17\t3.709485\tCloud9am\n",
    "18\t3.725421\tCloud3pm\n",
    "19\t21.318020\tTemp9am\n",
    "20\t46.827763\tTemp3pm\n",
    "21\t1.009367\tDay\n",
    "22\t1.248273\tMonth\n",
    "23\t2.249768\tYear\n",
    "Many feature are highly multi related So we will drop Temp3pm as it have highest VIF values\n",
    "\n",
    "x.drop('Temp3pm',axis=1,inplace=True)\n",
    "#Again Check VIF score\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF values\"] = [variance_inflation_factor(x.values,i)\n",
    "              for i in range(len(x.columns))]\n",
    "vif[\"Features\"] = x.columns\n",
    "\n",
    "# Let's check the values\n",
    "vif\n",
    "VIF values\tFeatures\n",
    "0\t1.475228\tWindGustDir\n",
    "1\t1.403688\tWindDir9am\n",
    "2\t1.307351\tWindDir3pm\n",
    "3\t1.900250\tRainToday\n",
    "4\t1.652686\tLocation\n",
    "5\t12.450665\tMinTemp\n",
    "6\t13.716104\tMaxTemp\n",
    "7\t2.337318\tRainfall\n",
    "8\t5.090933\tEvaporation\n",
    "9\t10.497546\tSunshine\n",
    "10\t3.792340\tWindGustSpeed\n",
    "11\t2.264903\tWindSpeed9am\n",
    "12\t2.951203\tWindSpeed3pm\n",
    "13\t4.439800\tHumidity9am\n",
    "14\t4.775954\tHumidity3pm\n",
    "15\t21.607362\tPressure9am\n",
    "16\t21.646353\tPressure3pm\n",
    "17\t3.686584\tCloud9am\n",
    "18\t3.698369\tCloud3pm\n",
    "19\t20.014874\tTemp9am\n",
    "20\t1.007291\tDay\n",
    "21\t1.213720\tMonth\n",
    "22\t2.248878\tYear\n",
    "#Now we will remove Pressure3pm\n",
    "x.drop('Pressure3pm',axis=1,inplace=True)\n",
    "#Again check VIF score\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF values\"] = [variance_inflation_factor(x.values,i)\n",
    "              for i in range(len(x.columns))]\n",
    "vif[\"Features\"] = x.columns\n",
    "\n",
    "# Let's check the values\n",
    "vif\n",
    "VIF values\tFeatures\n",
    "0\t1.474942\tWindGustDir\n",
    "1\t1.403227\tWindDir9am\n",
    "2\t1.278329\tWindDir3pm\n",
    "3\t1.894109\tRainToday\n",
    "4\t1.648175\tLocation\n",
    "5\t12.282022\tMinTemp\n",
    "6\t11.836635\tMaxTemp\n",
    "7\t2.298344\tRainfall\n",
    "8\t5.001804\tEvaporation\n",
    "9\t10.119354\tSunshine\n",
    "10\t3.781244\tWindGustSpeed\n",
    "11\t2.263416\tWindSpeed9am\n",
    "12\t2.929737\tWindSpeed3pm\n",
    "13\t4.439760\tHumidity9am\n",
    "14\t4.774847\tHumidity3pm\n",
    "15\t1.611483\tPressure9am\n",
    "16\t3.658018\tCloud9am\n",
    "17\t3.590936\tCloud3pm\n",
    "18\t19.954012\tTemp9am\n",
    "19\t1.005501\tDay\n",
    "20\t1.178931\tMonth\n",
    "21\t2.248053\tYear\n",
    "# Now We will remove Temp9am from our data\n",
    "x.drop('Temp9am',axis=1,inplace=True)\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF values\"] = [variance_inflation_factor(x.values,i)\n",
    "              for i in range(len(x.columns))]\n",
    "vif[\"Features\"] = x.columns\n",
    "\n",
    "# Let's check the values\n",
    "vif\n",
    "VIF values\tFeatures\n",
    "0\t1.474879\tWindGustDir\n",
    "1\t1.397777\tWindDir9am\n",
    "2\t1.275884\tWindDir3pm\n",
    "3\t1.893722\tRainToday\n",
    "4\t1.635427\tLocation\n",
    "5\t6.540286\tMinTemp\n",
    "6\t8.449583\tMaxTemp\n",
    "7\t2.295020\tRainfall\n",
    "8\t4.997755\tEvaporation\n",
    "9\t9.939048\tSunshine\n",
    "10\t3.701866\tWindGustSpeed\n",
    "11\t2.261178\tWindSpeed9am\n",
    "12\t2.818961\tWindSpeed3pm\n",
    "13\t3.246627\tHumidity9am\n",
    "14\t3.668927\tHumidity3pm\n",
    "15\t1.600776\tPressure9am\n",
    "16\t3.644286\tCloud9am\n",
    "17\t3.582916\tCloud3pm\n",
    "18\t1.005360\tDay\n",
    "19\t1.166643\tMonth\n",
    "20\t2.247961\tYear\n",
    "Now all feature were VIF values less than 10, let us proceed to modeling\n",
    "\n",
    "Clearing-Oversampling\n",
    "As we noticed Label values are not balanced\n",
    "\n",
    "# Oversampling the data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "SM = SMOTE()\n",
    "x, y = SM.fit_resample(x,y)\n",
    "# Checking value count of target column\n",
    "y.value_counts()\n",
    "0    3665\n",
    "1    3665\n",
    "Name: RainTomorrow, dtype: int64\n",
    "Modeling\n",
    "#Finding best random state\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "maxAccu=0\n",
    "maxRS=0\n",
    "for i in range(1,200):\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=.30, random_state =i)\n",
    "    DTC = RandomForestClassifier()\n",
    "    DTC.fit(x_train, y_train)\n",
    "    pred = DTC.predict(x_test)\n",
    "    acc=accuracy_score(y_test, pred)\n",
    "    if acc>maxAccu:\n",
    "        maxAccu=acc\n",
    "        maxRS=i\n",
    "print(\"Best accuracy is \",maxAccu,\" on Random_state \",maxRS)\n",
    "Best accuracy is  0.8835834470213734  on Random_state  54\n",
    "We have got the best random state as 54 and maximum accuracy as 88.35%\n",
    "\n",
    "# Creating train_test split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.30,random_state=maxRS)\n",
    "Classification Algorithms\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier, BaggingClassifier\n",
    "from xgboost import XGBClassifier as xgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "Random Forest Classifier\n",
    "# Checking accuracy for Random Forest Classifier\n",
    "RFC = RandomForestClassifier()\n",
    "RFC.fit(x_train,y_train)\n",
    "\n",
    "# Prediction\n",
    "predRFC = RFC.predict(x_test)\n",
    "rfc=accuracy_score(y_test, predRFC)\n",
    "print(rfc)\n",
    "print(confusion_matrix(y_test, predRFC))\n",
    "print(classification_report(y_test,predRFC))\n",
    "0.8799454297407913\n",
    "[[984 137]\n",
    " [127 951]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.89      0.88      0.88      1121\n",
    "           1       0.87      0.88      0.88      1078\n",
    "\n",
    "    accuracy                           0.88      2199\n",
    "   macro avg       0.88      0.88      0.88      2199\n",
    "weighted avg       0.88      0.88      0.88      2199\n",
    "\n",
    "The accuracy using Random Forest Classifier is 88%\n",
    "\n",
    "# Lets plot confusion matrix for RandomForestClassifier\n",
    "cm = confusion_matrix(y_test,predRFC)\n",
    "\n",
    "x_axis_labels = [\"NO\",\"YES\"]\n",
    "y_axis_labels = [\"NO\",\"YES\"]\n",
    "\n",
    "f , ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(cm, annot = True,linewidths=.2, linecolor=\"black\", fmt = \".0f\", ax=ax, cmap=\"cool\",xticklabels=x_axis_labels,yticklabels=y_axis_labels)\n",
    "\n",
    "plt.xlabel(\"PREDICTED LABEL\")\n",
    "plt.ylabel(\"TRUE LABEL\")\n",
    "plt.title('Confusion Matrix for RandomForestClassifier')\n",
    "plt.show()\n",
    "\n",
    "Support Vector Machine Classifier\n",
    "# Checking accuracy for Support Vector Machine Classifier\n",
    "svc = SVC()\n",
    "svc.fit(x_train,y_train)\n",
    "\n",
    "# Prediction\n",
    "predsvc = svc.predict(x_test)\n",
    "sv=accuracy_score(y_test, predsvc)\n",
    "print(sv)\n",
    "print(confusion_matrix(y_test, predsvc))\n",
    "print(classification_report(y_test,predsvc))\n",
    "0.7980900409276944\n",
    "[[878 243]\n",
    " [201 877]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.81      0.78      0.80      1121\n",
    "           1       0.78      0.81      0.80      1078\n",
    "\n",
    "    accuracy                           0.80      2199\n",
    "   macro avg       0.80      0.80      0.80      2199\n",
    "weighted avg       0.80      0.80      0.80      2199\n",
    "\n",
    "The accuracy score using Support Vector Machine classifier is 80%\n",
    "\n",
    "# Lets plot confusion matrix for Support Vector Machine Classifier\n",
    "cm = confusion_matrix(y_test,predsvc)\n",
    "\n",
    "x_axis_labels = [\"NO\",\"YES\"]\n",
    "y_axis_labels = [\"NO\",\"YES\"]\n",
    "\n",
    "f , ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(cm, annot = True,linewidths=.2, linecolor=\"black\", fmt = \".0f\", ax=ax, cmap=\"cool\",xticklabels=x_axis_labels,yticklabels=y_axis_labels)\n",
    "\n",
    "plt.xlabel(\"PREDICTED LABEL\")\n",
    "plt.ylabel(\"TRUE LABEL\")\n",
    "plt.title('Confusion Matrix for Support Vector Machine Classifier')\n",
    "plt.show()\n",
    "\n",
    "Gradient Boosting Classifier\n",
    "# Checking accuracy for Gradient Boosting Classifier\n",
    "GB = GradientBoostingClassifier()\n",
    "GB.fit(x_train,y_train)\n",
    "\n",
    "# Prediction\n",
    "predGB = GB.predict(x_test)\n",
    "\n",
    "gb=accuracy_score(y_test, predGB)\n",
    "print(gb)\n",
    "print(confusion_matrix(y_test, predGB))\n",
    "print(classification_report(y_test,predGB))\n",
    "0.8281036834924966\n",
    "[[937 184]\n",
    " [194 884]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.83      0.84      0.83      1121\n",
    "           1       0.83      0.82      0.82      1078\n",
    "\n",
    "    accuracy                           0.83      2199\n",
    "   macro avg       0.83      0.83      0.83      2199\n",
    "weighted avg       0.83      0.83      0.83      2199\n",
    "\n",
    "The accuracy using Gradient Boosting Classifier is 83%\n",
    "\n",
    "# Lets plot confusion matrix for Gradient Boosting Classifier\n",
    "cm = confusion_matrix(y_test,predGB)\n",
    "\n",
    "x_axis_labels = [\"NO\",\"YES\"]\n",
    "y_axis_labels = [\"NO\",\"YES\"]\n",
    "\n",
    "f , ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(cm, annot = True,linewidths=.2, linecolor=\"black\", fmt = \".0f\", ax=ax, cmap=\"cool\",xticklabels=x_axis_labels,yticklabels=y_axis_labels)\n",
    "\n",
    "plt.xlabel(\"PREDICTED LABEL\")\n",
    "plt.ylabel(\"TRUE LABEL\")\n",
    "plt.title('Confusion Matrix for Gradient Boosting Classifier')\n",
    "plt.show()\n",
    "\n",
    "Bagging Classifier\n",
    "# Checking accuracy for BaggingClassifier\n",
    "BC = BaggingClassifier()\n",
    "BC.fit(x_train,y_train)\n",
    "\n",
    "# Prediction\n",
    "predBC = BC.predict(x_test)\n",
    "bc=accuracy_score(y_test, predBC)\n",
    "print(bc)\n",
    "print(confusion_matrix(y_test, predBC))\n",
    "print(classification_report(y_test,predBC))\n",
    "0.8458390177353342\n",
    "[[971 150]\n",
    " [189 889]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.84      0.87      0.85      1121\n",
    "           1       0.86      0.82      0.84      1078\n",
    "\n",
    "    accuracy                           0.85      2199\n",
    "   macro avg       0.85      0.85      0.85      2199\n",
    "weighted avg       0.85      0.85      0.85      2199\n",
    "\n",
    "The accuracy using Bagging classifier is 85%\n",
    "\n",
    "# Lets plot confusion matrix for  Bagging Classifier\n",
    "cm = confusion_matrix(y_test,predBC)\n",
    "\n",
    "x_axis_labels = [\"NO\",\"YES\"]\n",
    "y_axis_labels = [\"NO\",\"YES\"]\n",
    "\n",
    "f , ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(cm, annot = True,linewidths=.2, linecolor=\"black\", fmt = \".0f\", ax=ax, cmap=\"cool\",xticklabels=x_axis_labels,yticklabels=y_axis_labels)\n",
    "\n",
    "plt.xlabel(\"PREDICTED LABEL\")\n",
    "plt.ylabel(\"TRUE LABEL\")\n",
    "plt.title('Confusion Matrix for  Bagging Classifier')\n",
    "plt.show()\n",
    "\n",
    "XGB Classifier\n",
    "# Checking accuracy for XGBClassifier\n",
    "XGB = xgb(verbosity=0)\n",
    "XGB.fit(x_train,y_train)\n",
    "\n",
    "# Prediction\n",
    "predXGB = XGB.predict(x_test)\n",
    "xgb1=accuracy_score(y_test, predXGB)\n",
    "print(xgb1)\n",
    "print(confusion_matrix(y_test, predXGB))\n",
    "print(classification_report(y_test,predXGB))\n",
    "0.8867667121418826\n",
    "[[1009  112]\n",
    " [ 137  941]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.88      0.90      0.89      1121\n",
    "           1       0.89      0.87      0.88      1078\n",
    "\n",
    "    accuracy                           0.89      2199\n",
    "   macro avg       0.89      0.89      0.89      2199\n",
    "weighted avg       0.89      0.89      0.89      2199\n",
    "\n",
    "The accuracy using XGB classifier is 89%\n",
    "\n",
    "# Lets plot confusion matrix for  XGBClassifier\n",
    "cm = confusion_matrix(y_test,predXGB)\n",
    "\n",
    "x_axis_labels = [\"NO\",\"YES\"]\n",
    "y_axis_labels = [\"NO\",\"YES\"]\n",
    "\n",
    "f , ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(cm, annot = True,linewidths=.2, linecolor=\"black\", fmt = \".0f\", ax=ax, cmap=\"cool\",xticklabels=x_axis_labels,yticklabels=y_axis_labels)\n",
    "\n",
    "plt.xlabel(\"PREDICTED LABEL\")\n",
    "plt.ylabel(\"TRUE LABEL\")\n",
    "plt.title('Confusion Matrix for  XGB Classifier')\n",
    "plt.show()\n",
    "\n",
    "Checking Cross Validation Score\n",
    "# cv score for Random Forest Classifier\n",
    "rf=cross_val_score(RFC,x,y,cv=5).mean()\n",
    "print(rf)\n",
    "0.5789904502046385\n",
    "# cv score for Support Vector Machine Classifier\n",
    "sv_cv=cross_val_score(svc,x,y,cv=5).mean()\n",
    "print(sv_cv)\n",
    "0.5934515688949522\n",
    "# cv score for Gradient Boosting Classifier\n",
    "gb_cv=cross_val_score(GB,x,y,cv=5).mean()\n",
    "print(gb_cv)\n",
    "0.47626193724420196\n",
    "# cv score for Bagging Classifier\n",
    "bc_cv=cross_val_score(BC,x,y,cv=5).mean()\n",
    "print(bc_cv)\n",
    "0.5376534788540246\n",
    "# cv score for XGB Classifier\n",
    "xgb_cv=cross_val_score(XGB,x,y,cv=5).mean()\n",
    "print(xgb_cv)\n",
    "0.48744884038199177\n",
    "model_list=['Random Forest Classifier','Support Vector Machine Classifier','Gradient Boosting Classifier','Bagging Classifier','XGB Classifier']\n",
    "accuracyscore=[rfc,sv,gb,bc,xgb1]\n",
    "crossval=[rf,sv_cv,gb_cv,bc_cv,xgb_cv]\n",
    "score_diff=[]\n",
    "for i in range(len(accuracyscore)):\n",
    "    score_diff.append(accuracyscore[i]-crossval[i])\n",
    "models=pd.DataFrame({})\n",
    "models[\"Classifier\"]=model_list#\n",
    "models[\"Accuracy_score\"]=accuracyscore\n",
    "models[\"Cross Validation_Score\"]=crossval\n",
    "models[\"Differance\"]=score_diff\n",
    "models\n",
    "Classifier\tAccuracy_score\tCross Validation_Score\tDifferance\n",
    "0\tRandom Forest Classifier\t0.879945\t0.578990\t0.300955\n",
    "1\tSupport Vector Machine Classifier\t0.798090\t0.593452\t0.204638\n",
    "2\tGradient Boosting Classifier\t0.828104\t0.476262\t0.351842\n",
    "3\tBagging Classifier\t0.845839\t0.537653\t0.308186\n",
    "4\tXGB Classifier\t0.886767\t0.487449\t0.399318\n",
    "So Support Vector Machine is the best model and has least differance value, so let us proceed\n",
    "\n",
    "Plotting ROC and compare AUC for all the models used\n",
    "# Plotting for all the models used here\n",
    "from sklearn import datasets \n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import plot_roc_curve \n",
    "\n",
    "\n",
    "disp=plot_roc_curve(svc, x_test, y_test)   # ax_=Axes with confusion matrix\n",
    "plot_roc_curve(RFC, x_test, y_test, ax=disp.ax_)\n",
    "\n",
    "plot_roc_curve(GB, x_test, y_test, ax=disp.ax_)\n",
    "plot_roc_curve(BC, x_test, y_test, ax=disp.ax_)\n",
    "plot_roc_curve(XGB, x_test, y_test, ax=disp.ax_)\n",
    "\n",
    "plt.legend(prop={'size':11}, loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "Hyper Parameter Tuning\n",
    "# Support Vector Classifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params={'C':[1,0.5,1.5],\n",
    "       'kernel' : ['linear', 'poly', 'rbf'],\n",
    "        'gamma' : ['scale', 'auto'],\n",
    "        'random_state':[100,200,150,250]}\n",
    "GCV=GridSearchCV(SVC(),params,cv=3)\n",
    "GCV.fit(x_train,y_train)\n",
    "GridSearchCV(cv=3, estimator=SVC(),\n",
    "             param_grid={'C': [1, 0.5, 1.5], 'gamma': ['scale', 'auto'],\n",
    "                         'kernel': ['linear', 'poly', 'rbf'],\n",
    "                         'random_state': [100, 200, 150, 250]})\n",
    "In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.\n",
    "On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.\n",
    "GCV.best_params_\n",
    "{'C': 1.5, 'gamma': 'auto', 'kernel': 'rbf', 'random_state': 100}\n",
    "These are the best parameters values that we have got for SVC\n",
    "\n",
    "FinalModel = SVC(C= 1.5, gamma='scale', kernel= 'rbf', random_state=100)\n",
    "FinalModel.fit(x_train, y_train)\n",
    "pred = FinalModel.predict(x_test)\n",
    "acc=accuracy_score(y_test,pred)\n",
    "print(acc*100)\n",
    "81.26421100500227\n",
    "So Accuracy of our final Clasification model is 81.26%\n",
    "\n",
    "# Lets plot confusion matrix for  FinalModel\n",
    "cm = confusion_matrix(y_test,pred)\n",
    "\n",
    "x_axis_labels = [\"NO\",\"YES\"]\n",
    "y_axis_labels = [\"NO\",\"YES\"]\n",
    "\n",
    "f , ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(cm, annot = True,linewidths=.2, linecolor=\"black\", fmt = \".0f\", ax=ax, cmap=\"ocean\",xticklabels=x_axis_labels,yticklabels=y_axis_labels)\n",
    "\n",
    "plt.xlabel(\"PREDICTED LABEL\")\n",
    "plt.ylabel(\"TRUE LABEL\")\n",
    "plt.title('Confusion Matrix for  Final Model')\n",
    "plt.show()\n",
    "\n",
    "Plotting ROC and Compare AUC for the best model\n",
    "# Let's check the Auc for the best model after hyper parameter tuning\n",
    "plot_roc_curve(FinalModel, x_test, y_test)\n",
    "plt.title(\"ROC for the best model\")\n",
    "plt.show()\n",
    "\n",
    "Save Classification model\n",
    "# Saving the model using .pkl\n",
    "import joblib\n",
    "joblib.dump(FinalModel,\"RainClassification.pkl\")\n",
    "['RainClassification.pkl']\n",
    "Predicting the saved model\n",
    "# Let's load the saved model and get the prediction\n",
    "\n",
    "# Loading the saved model\n",
    "model=joblib.load(\"RainClassification.pkl\")\n",
    "\n",
    "#Prediction\n",
    "prediction = model.predict(x_test)\n",
    "prediction\n",
    "array([1, 0, 0, ..., 0, 0, 0])\n",
    "a=np.array(y_test)\n",
    "Class_Result=pd.DataFrame({'Original':a,'Prediction':prediction})\n",
    "Class_Result\n",
    "Original\tPrediction\n",
    "0\t1\t1\n",
    "1\t0\t0\n",
    "2\t0\t0\n",
    "3\t0\t0\n",
    "4\t0\t0\n",
    "...\t...\t...\n",
    "2194\t1\t1\n",
    "2195\t1\t1\n",
    "2196\t0\t0\n",
    "2197\t0\t0\n",
    "2198\t0\t0\n",
    "2199 rows × 2 columns\n",
    "\n",
    "So we predicted RainTomorrow with our model, and Model Accuracy is 81.26%\n",
    "\n",
    " \n",
    "b) Design a predictive model with the use of machine learning algorithms to predict how much rainfall could be there.\n",
    "#Finding relation ith Rainfall\n",
    "plt.figure(figsize=(30,25))\n",
    "sns.heatmap(cor,linewidths=.1,vmin=-1, vmax=1, fmt='.1g',linecolor=\"black\", annot = True, annot_kws={'size':10},cmap=\"cool\")\n",
    "<AxesSubplot:>\n",
    "\n",
    "This gives Corelation with features and Labels, Now letuse check relation with Rainfall\n",
    "\n",
    "Visualizing the correlation between label and features using bar plot\n",
    "plt.figure(figsize=(20,10))\n",
    "new_df.corr()['Rainfall'].sort_values(ascending=False).drop(['Rainfall']).plot(kind='bar',color='y')\n",
    "plt.xlabel('Feature',fontsize=14)\n",
    "plt.ylabel('Target',fontsize=14)\n",
    "plt.title('correlation between label and feature using bar plot',fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "Almost all features have relation between Label, But only WindSpeed3pm does not have much relation\n",
    "\n",
    "Separating the features and label variables into x and y\n",
    "x = new_df.drop(\"Rainfall\", axis=1)\n",
    "y = new_df[\"Rainfall\"]\n",
    "Feature Scaling using Standard Scalarization\n",
    "scaler = StandardScaler()\n",
    "x = pd.DataFrame(scaler.fit_transform(x), columns=x.columns)\n",
    "x.head()\n",
    "WindGustDir\tWindDir9am\tWindDir3pm\tRainToday\tRainTomorrow\tLocation\tMinTemp\tMaxTemp\tEvaporation\tSunshine\t...\tHumidity3pm\tPressure9am\tPressure3pm\tCloud9am\tCloud3pm\tTemp9am\tTemp3pm\tDay\tMonth\tYear\n",
    "0\t1.247965\t1.213389\t1.541063\t-0.560882\t-0.565975\t-1.379334\t0.048488\t-0.226612\t-0.449326\t-0.154832\t...\t-1.588149\t-1.883671\t-1.502182\t1.479615\t0.327698\t-0.202854\t-0.185536\t-1.668284\t1.667302\t-1.743795\n",
    "1\t1.441737\t-0.358897\t1.779808\t-0.560882\t-0.565975\t-1.379334\t-1.001527\t0.145232\t-0.191372\t1.435521\t...\t-1.426422\t-1.357451\t-1.375007\t-1.110178\t-1.049117\t-0.150355\t0.247241\t-1.554771\t1.667302\t-1.743795\n",
    "2\t1.635509\t1.213389\t1.779808\t-0.560882\t-0.565975\t-1.379334\t-0.039013\t0.246644\t0.390325\t1.260313\t...\t-1.156876\t-1.901817\t-1.211498\t-0.682731\t-0.828466\t0.514633\t0.056819\t-1.441258\t1.667302\t-1.743795\n",
    "3\t-0.495982\t0.314940\t-1.801369\t-0.560882\t-0.565975\t-1.379334\t-0.686522\t0.635391\t-0.319826\t1.569545\t...\t-1.911604\t-0.087263\t-0.466621\t-1.348008\t-1.300868\t0.007143\t0.628084\t-1.327745\t1.667302\t-1.743795\n",
    "4\t1.247965\t-1.481959\t-0.130153\t-0.560882\t-0.565975\t-1.379334\t0.765999\t1.362178\t-0.272886\t-0.270022\t...\t-0.995149\t-1.321159\t-1.702027\t1.102344\t1.584544\t-0.045357\t1.182039\t-1.214232\t1.667302\t-1.743795\n",
    "5 rows × 24 columns\n",
    "\n",
    "We have scaled the data using standard scalarizaion .\n",
    "\n",
    "Checking Variance Inflation Factor(VIF)\n",
    "# Finding varience inflation factor in each scaled column i.e, x.shape[1] (1/(1-R2))\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF values\"] = [variance_inflation_factor(x.values,i)\n",
    "              for i in range(len(x.columns))]\n",
    "vif[\"Features\"] = x.columns\n",
    "\n",
    "# Let's check the values\n",
    "vif\n",
    "VIF values\tFeatures\n",
    "0\t1.472143\tWindGustDir\n",
    "1\t1.406864\tWindDir9am\n",
    "2\t1.309551\tWindDir3pm\n",
    "3\t1.260134\tRainToday\n",
    "4\t1.252099\tRainTomorrow\n",
    "5\t1.668373\tLocation\n",
    "6\t12.598002\tMinTemp\n",
    "7\t38.563117\tMaxTemp\n",
    "8\t5.093444\tEvaporation\n",
    "9\t10.510134\tSunshine\n",
    "10\t3.839655\tWindGustSpeed\n",
    "11\t2.275505\tWindSpeed9am\n",
    "12\t2.956867\tWindSpeed3pm\n",
    "13\t4.855465\tHumidity9am\n",
    "14\t7.110164\tHumidity3pm\n",
    "15\t22.562978\tPressure9am\n",
    "16\t22.440236\tPressure3pm\n",
    "17\t3.714303\tCloud9am\n",
    "18\t3.722789\tCloud3pm\n",
    "19\t21.304350\tTemp9am\n",
    "20\t46.829453\tTemp3pm\n",
    "21\t1.009229\tDay\n",
    "22\t1.241119\tMonth\n",
    "23\t2.254699\tYear\n",
    "#Let us remove Temp3pm\n",
    "x.drop('Temp3pm',axis=1,inplace=True)\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF values\"] = [variance_inflation_factor(x.values,i)\n",
    "              for i in range(len(x.columns))]\n",
    "vif[\"Features\"] = x.columns\n",
    "\n",
    "# Let's check the values\n",
    "vif\n",
    "VIF values\tFeatures\n",
    "0\t1.471769\tWindGustDir\n",
    "1\t1.405986\tWindDir9am\n",
    "2\t1.309222\tWindDir3pm\n",
    "3\t1.259898\tRainToday\n",
    "4\t1.252052\tRainTomorrow\n",
    "5\t1.665915\tLocation\n",
    "6\t12.426289\tMinTemp\n",
    "7\t13.696958\tMaxTemp\n",
    "8\t5.090762\tEvaporation\n",
    "9\t10.495494\tSunshine\n",
    "10\t3.790547\tWindGustSpeed\n",
    "11\t2.263777\tWindSpeed9am\n",
    "12\t2.955705\tWindSpeed3pm\n",
    "13\t4.278061\tHumidity9am\n",
    "14\t4.893234\tHumidity3pm\n",
    "15\t21.162651\tPressure9am\n",
    "16\t21.306203\tPressure3pm\n",
    "17\t3.691260\tCloud9am\n",
    "18\t3.695588\tCloud3pm\n",
    "19\t19.999913\tTemp9am\n",
    "20\t1.007150\tDay\n",
    "21\t1.206650\tMonth\n",
    "22\t2.253784\tYear\n",
    "x.drop('Temp9am',axis=1,inplace=True)\n",
    "vif = pd.DataFrame()#Again check the value of VIF\n",
    "vif[\"VIF values\"] = [variance_inflation_factor(x.values,i)\n",
    "              for i in range(len(x.columns))]\n",
    "vif[\"Features\"] = x.columns\n",
    "\n",
    "# Let's check the values\n",
    "vif\n",
    "VIF values\tFeatures\n",
    "0\t1.471658\tWindGustDir\n",
    "1\t1.400894\tWindDir9am\n",
    "2\t1.305669\tWindDir3pm\n",
    "3\t1.259724\tRainToday\n",
    "4\t1.251821\tRainTomorrow\n",
    "5\t1.652572\tLocation\n",
    "6\t6.784112\tMinTemp\n",
    "7\t10.048678\tMaxTemp\n",
    "8\t5.084177\tEvaporation\n",
    "9\t10.348746\tSunshine\n",
    "10\t3.719694\tWindGustSpeed\n",
    "11\t2.261437\tWindSpeed9am\n",
    "12\t2.853401\tWindSpeed3pm\n",
    "13\t3.112288\tHumidity9am\n",
    "14\t3.780215\tHumidity3pm\n",
    "15\t21.026659\tPressure9am\n",
    "16\t21.231649\tPressure3pm\n",
    "17\t3.675205\tCloud9am\n",
    "18\t3.690719\tCloud3pm\n",
    "19\t1.006931\tDay\n",
    "20\t1.191429\tMonth\n",
    "21\t2.253622\tYear\n",
    "x.drop('Pressure3pm',axis=1,inplace=True)# Droping Pressure3pm\n",
    "vif = pd.DataFrame()#Again check the value of VIF\n",
    "vif[\"VIF values\"] = [variance_inflation_factor(x.values,i)\n",
    "              for i in range(len(x.columns))]\n",
    "vif[\"Features\"] = x.columns\n",
    "\n",
    "# Let's check the values\n",
    "vif\n",
    "VIF values\tFeatures\n",
    "0\t1.471599\tWindGustDir\n",
    "1\t1.400403\tWindDir9am\n",
    "2\t1.278061\tWindDir3pm\n",
    "3\t1.258340\tRainToday\n",
    "4\t1.250531\tRainTomorrow\n",
    "5\t1.648729\tLocation\n",
    "6\t6.453127\tMinTemp\n",
    "7\t8.383874\tMaxTemp\n",
    "8\t4.999981\tEvaporation\n",
    "9\t9.967566\tSunshine\n",
    "10\t3.712031\tWindGustSpeed\n",
    "11\t2.259805\tWindSpeed9am\n",
    "12\t2.830677\tWindSpeed3pm\n",
    "13\t3.112249\tHumidity9am\n",
    "14\t3.779236\tHumidity3pm\n",
    "15\t1.588481\tPressure9am\n",
    "16\t3.648429\tCloud9am\n",
    "17\t3.583956\tCloud3pm\n",
    "18\t1.005370\tDay\n",
    "19\t1.162400\tMonth\n",
    "20\t2.253067\tYear\n",
    "Now all features VIF values are below 10, So we can proceed\n",
    "\n",
    "Modeling\n",
    "#Finding best random state\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "maxAccu=0\n",
    "maxRS=0\n",
    "for i in range(1,200):\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=.30, random_state =i)\n",
    "    RFG = RandomForestRegressor()\n",
    "    RFG.fit(x_train, y_train)\n",
    "    pred = RFG.predict(x_test)\n",
    "    acc=r2_score(y_test, pred)\n",
    "    if acc>maxAccu:\n",
    "        maxAccu=acc\n",
    "        maxRS=i\n",
    "print(\"Best accuracy is \",maxAccu,\" on Random_state \",maxRS)\n",
    "Best accuracy is  0.749510648622342  on Random_state  156\n",
    "So The Best Accuracy is 74.95 % at Rando State 156\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.30,random_state=maxRS)     #Creating at best Random State\n",
    "Regression Algorithms\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor as KNN\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "Random Forest Regressor\n",
    "# Checking R2 score for Random Forest Regressor\n",
    "RFR=RandomForestRegressor()\n",
    "RFR.fit(x_train,y_train)\n",
    "\n",
    "# prediction\n",
    "predRFR=RFR.predict(x_test)\n",
    "print('R2_Score:',r2_score(y_test,predRFR))\n",
    "print('MAE:',mean_absolute_error(y_test, predRFR))\n",
    "print('MSE:',mean_squared_error(y_test, predRFR))\n",
    "print(\"RMSE:\",np.sqrt(mean_squared_error(y_test, predRFR)))\n",
    "# Checking cv score \n",
    "print(cross_val_score(RFR,x,y,cv=5).mean())\n",
    "R2_Score: 0.7530560377098292\n",
    "MAE: 0.2509616051041776\n",
    "MSE: 0.16337550547314572\n",
    "RMSE: 0.4041973595573649\n",
    "0.4634332799176722\n",
    "Accuracy of Random Forest Regressor is 75.30%\n",
    "\n",
    "KNNeighbors Regressor\n",
    "# Checking R2 score for Stochastic KNN Regressor\n",
    "knn=KNN()\n",
    "knn.fit(x_train,y_train)\n",
    "\n",
    "# prediction\n",
    "predknn=knn.predict(x_test)\n",
    "print('R2_Score:',r2_score(y_test,predknn))\n",
    "print('MAE:',mean_absolute_error(y_test, predknn))\n",
    "print('MSE:',mean_squared_error(y_test, predknn))\n",
    "print(\"RMSE:\",np.sqrt(mean_squared_error(y_test, predknn)))\n",
    "# Checking cv score \n",
    "print(cross_val_score(knn,x,y,cv=5).mean())\n",
    "R2_Score: 0.6231677519288155\n",
    "MAE: 0.2835365012376504\n",
    "MSE: 0.2493082172823875\n",
    "RMSE: 0.4993077380557881\n",
    "0.38874628193123617\n",
    "Accuracy of KNNeighbors Regressor is 62.31%\n",
    "\n",
    "GradientBoosting Regressor\n",
    "# Checking R2 score for GradientBoosting Regressor\n",
    "GB=GradientBoostingRegressor()\n",
    "GB.fit(x_train,y_train)\n",
    "\n",
    "# prediction\n",
    "predGB=GB.predict(x_test)\n",
    "print('R2_Score:',r2_score(y_test,predGB))\n",
    "print('MAE:',mean_absolute_error(y_test, predGB))\n",
    "print('MSE:',mean_squared_error(y_test, predGB))\n",
    "print(\"RMSE:\",np.sqrt(mean_squared_error(y_test, predGB)))\n",
    "# Checking cv score \n",
    "\n",
    "print(cross_val_score(GB,x,y,cv=5).mean())\n",
    "R2_Score: 0.7308151542672126\n",
    "MAE: 0.26752738408775983\n",
    "MSE: 0.17808983799178066\n",
    "RMSE: 0.42200691699518467\n",
    "0.42431876987359834\n",
    "Accuracy for Gradient Boosting is 73.08%\n",
    "\n",
    "BaggingRegressor\n",
    "# Checking R2 score for BaggingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "BR=BaggingRegressor()\n",
    "BR.fit(x_train,y_train)\n",
    "\n",
    "# prediction\n",
    "predBR=BR.predict(x_test)\n",
    "print('R2_Score:',r2_score(y_test,predBR))\n",
    "print('MAE:',mean_absolute_error(y_test, predBR))\n",
    "print('MSE:',mean_squared_error(y_test, predBR))\n",
    "print(\"RMSE:\",np.sqrt(mean_squared_error(y_test, predBR)))\n",
    "# Checking cv score\n",
    "print(cross_val_score(BR,x,y,cv=5).mean())\n",
    "R2_Score: 0.7223899014704565\n",
    "MAE: 0.2585877329596337\n",
    "MSE: 0.18366389585350565\n",
    "RMSE: 0.4285602593025929\n",
    "0.42284567502677833\n",
    "Accuracy for Bagging algorithm is 72.23%\n",
    "\n",
    "AdaBoostRegressor\n",
    "ABR=AdaBoostRegressor()\n",
    "\n",
    "ABR.fit(x_train,y_train)\n",
    "# prediction\n",
    "predABR=ABR.predict(x_test)\n",
    "print('R2_Score:',r2_score(y_test,predABR))\n",
    "print('MAE:',mean_absolute_error(y_test, predABR))\n",
    "print('MSE:',mean_squared_error(y_test, predABR))\n",
    "print(\"RMSE:\",np.sqrt(mean_squared_error(y_test, predABR)))\n",
    "# Checking cv score\n",
    "print(cross_val_score(ABR,x,y,cv=5).mean())\n",
    "R2_Score: 0.3571147887775481\n",
    "MAE: 0.5922628390372223\n",
    "MSE: 0.4253260349862733\n",
    "RMSE: 0.6521702500009283\n",
    "0.21193541957297599\n",
    "From this we can AdaboostRegressor as our Best Algorithm as leaset differance between r2 score and CVR score\n",
    "\n",
    "Hyper parameter tuning\n",
    "parameter={'n_estimators':[1,3,4,5],\n",
    "          'learning_rate':[.1,1,.3,.5],\n",
    "          'loss' : ['linear', 'square', 'exponential'],\n",
    "          'random_state':[100,150,200,250]}\n",
    "GCV=GridSearchCV(AdaBoostRegressor(),parameter,cv=4)\n",
    "GCV.fit(x_train,y_train)\n",
    "GridSearchCV(cv=4, estimator=AdaBoostRegressor(),\n",
    "             param_grid={'learning_rate': [0.1, 1, 0.3, 0.5],\n",
    "                         'loss': ['linear', 'square', 'exponential'],\n",
    "                         'n_estimators': [1, 3, 4, 5],\n",
    "                         'random_state': [100, 150, 200, 250]})\n",
    "In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.\n",
    "On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.\n",
    "GCV.best_params_\n",
    "{'learning_rate': 0.3,\n",
    " 'loss': 'square',\n",
    " 'n_estimators': 5,\n",
    " 'random_state': 100}\n",
    "Rainfall_model = AdaBoostRegressor(learning_rate= 1, loss= 'exponential',n_estimators= 3,random_state=100)\n",
    "Rainfall_model.fit(x_train, y_train)\n",
    "pred = Rainfall_model.predict(x_test)\n",
    "print(\"RMSE value:\",np.sqrt(mean_squared_error(y_test, pred)))\n",
    "print('R2_Score:',r2_score(y_test,pred)*100)\n",
    "RMSE value: 0.4911751105925623\n",
    "R2_Score: 63.53433220539183\n",
    "So our accuracy of our Final Regressor model increased to 63.53%\n",
    "\n",
    "Saving the model\n",
    "# Saving the model using .pkl\n",
    "import joblib\n",
    "joblib.dump(Rainfall_model,\"RainfallRegressor.pkl\")\n",
    "['RainfallRegressor.pkl']\n",
    "Let's load the saved model and get the prediction\n",
    "# Loading the saved model\n",
    "model=joblib.load(\"RainfallRegressor.pkl\")\n",
    "\n",
    "#Prediction\n",
    "prediction = model.predict(x_test)\n",
    "a = np.array(y_test)\n",
    "df_final = pd.DataFrame({\"Original\":a,\"Predicted\":prediction},index=range(len(a)))\n",
    "df_final\n",
    "Original\tPredicted\n",
    "0\t1.192691\t1.032945\n",
    "1\t-0.775140\t-0.010484\n",
    "2\t1.238711\t1.032945\n",
    "3\t-0.775140\t-0.231061\n",
    "4\t-0.775140\t-0.172792\n",
    "...\t...\t...\n",
    "1447\t1.204859\t-0.231061\n",
    "1448\t-0.775140\t-0.710928\n",
    "1449\t0.556492\t-0.480672\n",
    "1450\t-0.775140\t-0.515951\n",
    "1451\t-0.775140\t-0.677420\n",
    "1452 rows × 2 columns\n",
    "\n",
    "Thank You\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
